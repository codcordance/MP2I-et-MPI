\documentclass[a4paper,french,bookmarks]{book}

\usepackage{booktabs}
\usepackage{minitoc}
\usepackage{./Structure/4PE18TEXTB}
\usepackage{proof}
\usepackage{pdfpages}

\makeatletter
\renewcommand*\l@section{\@dottedtocline{1}{1.8em}{3.5em}}
\renewcommand*\l@subsection{\@dottedtocline{2}{5.3em}{3.5em}}
\makeatother

\newboxans
\renewcommand{\thechapter}{\Roman{chapter}}
\renewcommand{\thesubsection}{\thesection.\Alph{subsection}}
\mtcsettitle{minitoc}{}

\DeclareDocumentCommand\Sp{g}{\funlv{Sp}{#1}}

\newcommand{\chaptertoc}[0]{
    \setcounter{tocdepth}{2}
    \begin{tcolorbox}[
        enhanced,
        frame hidden,
        sharp corners,
        detach title,
        spread outwards     = 5pt,
        halign              = center,
        valign              = center,
        borderline west     = {3pt}{0pt}{main20!50!main2!95!gray!90},
        coltitle            = main20!50!main2!95!gray!90, 
        interior style      = {
            left color      = main1white2!65!gray!11,
            middle color    = main1white2!50!gray!10,
            right color     = main1white2!35!gray!9
        },
        arc                 = 0 cm,
        title               = SOMMAIRE,
        boxrule             = 0pt,
        fonttitle           = \bfseries\sffamily,
        overlay             = {
            \node[rotate=90, minimum width=1cm, anchor=south,yshift=-0.8cm]
            at (frame.west) {\tcbtitle};
        }
    ]
        \begin{minipage}{0.83\linewidth}
            \sffamily
            \minitoc
        \end{minipage}
    \end{tcolorbox}
}

\begin{document}
    
    %==============================
    % METADONNEES
    %==============================
    
    \title{Cours de Mathématiques de MPI/MPI* (2022-2023)}
    \author{SIAHAAN--GENSOLLEN Rémy}
    \date{\today}
    \hypersetup{
        pdftitle={Cours de Mathématiques de MPI/MPI* (2022-2023)},
        pdfauthor={SIAHAAN--GENSOLLEN Rémy},
        pdflang={fr-FR},
        pdfsubject={MPI/MPI*, Cours de Mathématiques},
        pdfkeywords={MPI/MPI*, Cours de Mathématiques, 2022-2023}
        pdfstartview=
    }
    
    %==============================
    % MISE EN PAGE
    %==============================
    
    \titleformat{\chapter}[display]{\normalfont\huge\bfseries}{}{0pt}{
        \begin{tcolorbox}[
            enhanced,
            frame hidden,
            sharp corners,
            spread sidewards    = 5pt,
            halign              = center,
            valign              = center,
            interior style      = {color=main1!20},
            arc                 = 0 cm,
            fontupper           = \color{black}\sffamily\bfseries\huge,
            fonttitle           = \normalfont\color{white}\sffamily\small,
            top                 = 1cm, 
            bottom              = 0.7cm,
            title               = Chapitre \thechapter,
            attach boxed title to bottom center = {
                yshift=\tcboxedtitleheight/2,
            },
            boxed title style = {
                frame code={
                \path[left color=main2!95!gray!90,
                right color=main1!95!gray!90] 
                    ([xshift=-10mm]frame.north west) -- 
                    ([xshift=10mm]frame.north east) -- 
                    ([xshift=10mm]frame.south east) -- 
                    ([xshift=-10mm]frame.south west) -- 
                    cycle;
                },
                interior engine=empty
            }
        ]
            #1
        \end{tcolorbox}%
    }
    \titlespacing*{\chapter}{0pt}{-120pt}{-15pt}
    \titleformat{name=\chapter,numberless}[display]{\normalfont\huge\bfseries}
    {}{0pt}{
        \begin{tcolorbox}[
            enhanced,
            frame hidden,
            sharp corners,
            spread sidewards    = 5pt,
            halign              = center,
            valign              = center,
            interior style      = {color=main1!20},
            arc                 = 0 cm,
            outer arc           = 0pt,
            leftrule            = 0pt,
            rightrule           = 0pt,
            fontupper           = \color{black}\sffamily\bfseries\huge,
            enlarge left by     = -1in-\hoffset-\oddsidemargin, 
            enlarge right by    = -\paperwidth+1in+\hoffset +
            \oddsidemargin+\textwidth,
            width               = \paperwidth, 
            left                = 1in+\hoffset+\oddsidemargin, 
            right               = \paperwidth-1in-\hoffset -
            \oddsidemargin-\textwidth,
            top                 = 1cm, 
            bottom              = 1cm
        ]
            #1
        \end{tcolorbox}%
    }
    \titlespacing*{name=\chapter,numberless}{0pt}{-115pt}{0pt}
    
    %==============================
    % PREMIERE DE COUVERTURE
    %==============================

    \includepdf[pages={1},scale=1.15,offset=0mm -18mm]{CMCover.pdf}
    
    %==============================
    % PAGE VIDE
    %==============================
    
    \pagestyle{empty}
    
    %==============================
    % PAGE DE COUVERTURE INTERNE
    %==============================
    
    \begin{titlepage}
	    \begin{center}
	        {\scshape SIAHAAN--GENSOLLEN Rémy\par}
	        \vspace{2cm}
	        {\huge\sffamily Cours de\par}
	        \vspace{0.5cm}
	        {\Huge\bfseries\sffamily MATHÉMATIQUES\par}
	        \vspace{1cm}
	        {\Large\textit{donné pendant mon année de \textsf{MPI/MPI*} à
	        Janson-de-Sailly}\\[5pt]\texttt{(2022-2023)}\par}
	        \vfill
	        {\large\EBGaramond Dernière compilation le \today\par}
        \end{center}
    \end{titlepage}
    
    %==============================
    % PAGE VIDE
    %==============================
    
    \pagestyle{empty}\text{}\newpage
    
    %==============================
    % STYLE DES EN-TÊTES ET PIEDS DE PAGES
    %==============================
    
    \renewcommand\chaptermark[1]{\markboth{#1}{}}
    
    \fancypagestyle{intro}{
        \fancyhf{}
        \renewcommand{\headrulewidth}{0pt}
        \renewcommand{\footrulewidth}{0pt}\fancyfoot[RO,LE]{\GillSansMTMedium\color{white5}\thepage\;/\;\pageref{LastPage}}
        \fancyhead[LE]{\GillSansMTMedium\color{white5}\bfseries COURS DE MATHÉMATIQUES}
        \fancyhead[RE]{\GillSansMTMedium\color{white5}Avant-propos}
        \fancyhead[LO]{\GillSansMTMedium\color{white5}\rightmark}
        \fancyhead[RO]{\GillSansMTMedium\color{white5}\textbf{MPI/MPI*} 2022-2023 \quad Janson-de-Sailly}
    }
    
    \fancypagestyle{toc}{
        \fancyhf{}
        \renewcommand{\headrulewidth}{0pt}
        \renewcommand{\footrulewidth}{0pt}\fancyfoot[RO,LE]{\GillSansMTMedium\color{white5}\thepage\;/\;\pageref{LastPage}}
        \fancyhead[LE]{\GillSansMTMedium\color{white5}\bfseries COURS DE MATHÉMATIQUES}
        \fancyhead[RE]{\GillSansMTMedium\color{white5}Table des matières}
        \fancyhead[LO]{\GillSansMTMedium\color{white5}\rightmark}
        \fancyhead[RO]{\GillSansMTMedium\color{white5}\textbf{MPI/MPI*} 2022-2023 \quad Janson-de-Sailly}
    }
    
    \fancypagestyle{plain}{
        \fancyhf{}
        \renewcommand{\headrulewidth}{0pt}
        \renewcommand{\footrulewidth}{0pt}\fancyfoot[RO,LE]{\GillSansMTMedium\color{white5}\thepage\;/\;\pageref{LastPage}}
        \fancyhead[LE]{\GillSansMTMedium\color{white5}\bfseries COURS DE MATHÉMATIQUES}
        \fancyhead[RE]{\GillSansMTMedium\color{white5}Chapitre \thechapter : \nouppercase{\leftmark}}
        \fancyhead[LO]{\GillSansMTMedium\color{white5}\nouppercase{\rightmark}}
        \fancyhead[RO]{\GillSansMTMedium\color{white5}\textbf{MPI/MPI*} 2022-2023 \quad Janson-de-Sailly}
    }
    
    %==============================
    % PREFACE 
    %==============================
    
    \chapter*{Avant-propos}
    \thispagestyle{intro}
    \addcontentsline{toc}{chapter}{Avant-propos}
    
    \text{\Large\EBGaramond\itshape À tout lecteur potentiel, quelques mots...}\newline\newline\newline
    
    \begin{center}
        \begin{minipage}{0.85\linewidth}
            \large \qquad Comme son nom l'indique, l'objectif de cet ouvrage est de fournir un cours de Mathématiques en accord avec le programme des classes préparatoires \textsf{MPI/MPI*}. Il contiendra principalement des notes de cours, dont je serai dispensé mon année de \guill{spé'} (année 2022/2023) à \textit{Janson-de-Sailly}, par M. \textsc{Luc Abergel}. J'essaierai par ailleurs de détailler et d'enrichir le plus possible son contenu au fil de l'année, à l'aide de mes cours de première année, d'autres ouvrages et de recherches en général. La rédaction de ce cours constitue un important projet, d'autant plus que j'en mène un similaire pour les enseignements d'informatique et de physique cette année. C'est un travail qui peut s'avérer extrêmement chronophage, aussi risque-t-il d'être rarement mené jusqu'au bout.\newline
    
            \qquad Je ne prétends à aucun moment être enseignant, et ce livre reste avant tout destiné à mon usage personnel, aussi j'aviserai tout lecteur potentiel à faire preuve de prudence lors du parcours de ce texte, à ne pas hésiter à en vérifier le contenu par lui même. Il est très probable que de multiples erreurs (en tout genre) se soient glissés durant la rédaction, que je n'aurait su repérer, ou que le manque de temps empêche la correction. N'hésitez d'ailleurs pas à me le signaler, ou à me faire part de vos remarques en général.\newline
    
            \qquad J'espère enfin, et malgré les points exprimés précédemment, que ce cours pourra avoir une quelconque utilité à ceux qui s'y aventureraient, que sa lecture et son style en seront agréable (la mise en page et la composition graphique en général sont de ma conception personnelle, enrichie par les retours de mes camarades, et le fruit de plusieurs mois d'apprentissage de \LaTeX) et enrichissante.\newline\newline\newline\text{}
        \end{minipage}
    \end{center}
    
    \hfill{\large\textsc{Siahaan--Gensollen Rémy}}
    
    \pagestyle{intro}
    
    %==============================
    % TABLE DES MATIERES
    %==============================
    
    \newpage
    \dominitoc\nomtcrule 
    {\sffamily\tableofcontents}\mtcaddchapter\pagestyle{toc}
    
    \cleardoublepage
    
    %==============================
    % COURS
    %==============================
    
    \pagestyle{plain}
    
    \chapter{Espaces vectoriels généraux}
    
    Intro
    
    \chaptertoc
    
    \section{Présentation}
    
    \begin{definition}{Corps commutatif}{}
        Soit un \hg{anneau commutatif $\p{\bdK, +, x}$}. On dit que \hg{$\p{\bdK, +, x}$ est un corps commutatif} lorsque \hg{tout élément \textit{non nul} de $\bdK$ admet un inverse}.
    \end{definition}
    
    \begin{example}{}{}
        \begin{enumerate}
            \itt $\bdQ$, $\bdR$, $\bdC$ sont des corps commutatifs.
            
            \itt $\bdF_p = \bdZ/p\bdZ$ pour un entier premier $p \in \bdP$ est un corps commutatif.
            
            \itt $\bdQ\intc{\sqrt{2}} = \ens{a + b\sqrt{2}?\ \p{a, b} \in \bdQ^2}$ est un corps commutatif. En effet, on peut utiliser la multiplication par la quantité conjuguée :
            %
            \[ \dfrac{1}{a + b \sqrt{2}} = \dfrac{a - b\sqrt{2}}{a^2 - 2b^2}\]
            %
            Question : montrer que pour $\p{a, b} \in \bdQ^2$, on a $a^2 - 2b^2 = 0 \iff a = b = 0$
            
            \itt Soit le corps $\bck = \bdZ/3\bdZ$. On remarque que $0^2 = 0$, $1^1 = 1$ et $2^2 = 1$ donc $x^2 = 2$ n'a pas de solution dans $\bck$. On pose alors $\alpha$ tel que $\alpha^2 = 2 \in k$.
        \end{enumerate}
    \end{example}
    
    \begin{definition}{Caractéristique (HP)}{}
        Soit un \hg{anneau commutatif $\p{\bdA, +, x}$} de \hg{neutre additif $0_\bdA$} et \hg{neutre multiplicatif $1_\bdA$}.
        %
        On appelle \hg{caractéristique de l'anneau $\p{\bdA, +, x}$} le \hg{plus \textit{petit entier} $n \in \bdN$} tel que :
        %
        \[ \hg{n \times 1_A = \underbrace{1_\bdA + 1_\bdA + \dots + 1_\bdA}_{n \ \text{fois}} = 0_\bdA} \]
        %
        \hg{si un tel entier existe, sinon égale à $0$}.
    \end{definition}
    
    Grossièrement, on se contentera de la compréhension suivante pour les corps :
    %
    \begin{enumerate}
        \itt Pour un corps $\bdK \subset \bdC$, la caractéristique de $\bdK$ est nulle.
        
        \itt Pour un corps $\bdK = \bdF_p = \bdZ/p\bdZ$ avec $p \in \bdP$, la caractéristique de $\bdK$ vaut $p$. 
    \end{enumerate}
    
    
    \section{Objets de l'algèbre linéaire}
    
    Rappels de SUP
    
    \section{Dimension}
    
    On considère une famille libre $\bsL = \p{e_i}_{i \in \iint{1, n}}$
    
    \newpage
    
    \begin{property}{Rang d'une composition}{}
        \[ \hg{\rg{uv} \leq \min{\rg u, \rg v}}\]
        
        Si $u$ est un isomorphisme, alors $\rg{uv} = \rg{v}$, et si $v$ est un isomorphisme, alors $\rg{uv} = \rg{u}$.
    \end{property}
    
    \begin{nproof}
        $\Imm\p{uv} = u\p{\Imm v} < \Imm u$.
        
        Si $v$ est un isomorphisme, $\Imm\p{uv} = u\p{\Imm v} = u\p{E} = \Imm{u}$. Donc $\rg{uv} = \rg u$.
    \end{nproof}
    
    \begin{property*}{}{}
        Soit \hg{$F$} un \hg{$\bdK$-espace vectoriel}. On a l'\hg{isomorphisme} :
        %
        \[ \hg{\bcL\p{\bdK, F} \cong F}\]
        %
    \end{property*}
    %
    \begin{nproof}
        Soit $F$ un $\bdK$-ev. Soit un vecteur $x \in F$. On construit $f_x : \bdK \to F$ telle que $\forall \lambda \in \bdK,\qquad f_x\p{\lambda} = \lambda x$. On obtient facilement que $f_x$ est linéaire. On pose alors $\bch : F \to \bcL\p{\bdK, F}$ l'application qui à $x$ associe $f_x$.
        %
        \begin{enumerate}
            \itt Soit $\p{x, y} \in F$ et $\lambda \in \bdK$, on a :
            %
            \[ \forall \mu \in \bdK,\qquad \bch\p{\lambda x + y}\p{\mu} = \mu\p{\lambda x + y} = \mu\lambda x + \mu y = \lambda \bch\p{x}\p{\mu} + \bch\p{y}\p{\mu} \]
            %
            D'où $\bch\p{\lambda x + y} = \lambda \bch\p{x} +  \bch\p{y}$. $\bch$ est donc linéaire.
            %
            \itt Soit une application $f$ de $\bcL\p{\bdK, F}$. On pose $x = f\p{1}$. Par linéarité, pour tout scalaire $\lambda \in \bdK$, on a $f\p{\lambda} = \lambda x$. Donc $f = \bch\p{x}$. Ainsi $\bch$ est surjective.
            
            \itt Soit $\p{x} \in F$ tel que $\bch\p{x} = 0_{\bcL\p{\bdK, F}}$. Alors $\bch\p{x}\p{1} = 0$. Or $\bch\p{x}\p{1} = x$ donc $x = 0$. $\bch$ est donc injective.
        \end{enumerate}
        %
        $\bch$ est bien un isomorphisme, d'où $\bcL\p{\bdK, F} \cong F$.
    \end{nproof}
    
    \begin{property*}{}{}
        Soit \hg{$E$} et \hg{$F$} deux \hg{$\bdK$-espaces vectoriels} de \hg{dimension finie}, \hg{$H \subset F$} un \hg{sous espace vectoriel} et \hg{$u \in \bcL\p{E, F}$} une \hg{application linéaire de $E$ dans $F$}. On a :
        %
        \[ \hg{\dim{u^{-1}\p{H}} = \dim{H \cap \Imm u} + \dim{\Ker u}}\]
    \end{property*}
    
    \begin{nproof}
        Soit $E$ et $F$ deux $\bdK$-espaces vectoriels de dimension finie, $H \subset F$ un sous espace vectoriel et $u \in \bcL\p{E, F}$ une application linéaire de $E$ dans $F$. On pose $\overline{u} = u_{\mid u^{-1}\p{H}}$ la restriction de $u$ à $u^{-1}\p{H}$. Par \textit{théorème du rang} sur $\overline{u}$, on a : 
        %
        \[ \dim{u^{-1}\p{H}} = \dim{\Imm \overline{u}} + \dim{\Ker \overline{u}}\]
        %
        \begin{enumerate}
            \itt On a $\Imm{\overline{u}} = \ens{u\p{x},\ x \in u^{-1}\p{H}} = H \cap \Imm{u}$.
            
            \itt De plus, $\Ker \overline{u} = \ens{x \in u^{-1}\p{H} \enstq u\p{x} = 0} \subset \Ker u$. Par ailleurs, si $x \in \Ker u$, alors $u\p{x} = 0$. Or $0 \in H$ donc $x \in u^{-1}\p{H}$, donc $\overline{u}\p{x} = 0$, d'où $x \in \Ker \overline{u}$. Ainsi $\Ker u \subset \Ker \overline{u}$, donc $\Ker u = \Ker \overline{u}$.
        \end{enumerate}
        %
        On obtient bien :
        %
        \[ \dim{u^{-1}\p{H}} = \dim{H \cap \Imm u} + \dim{\Ker u}\]
    \end{nproof}
    
    \chapter{Matrices}
    
    \chaptertoc
    
    \section{Présentation de $\bcM_{n, m}\p{\bdK}$}
    
    \subsection{Définition}
    
    \begin{definition}{Matrice}{}
        Une matrice est une famille doublement indexée $\p{a_{i, j}}_{\p{i, j} \in \iint{1, n} \times \iint{1, m}}$ avec $a_{i, j} \in \bdK$.
    \end{definition}
    
    
    \begin{definition}{Ensemble des matrices}{}
        L'ensemble des matrices est noté $\bcM_{n, m}\p{\bdK}$
    \end{definition}
    
    \begin{definition}{Colonnes et lignes}{}
        La colonne d'une matrice $M$ est le vecteur/la famille $\bsC_j\p{M} = \p{a_{i, j}}_{i \in \iint{1, n}} = \p{a_{i, j}}_i$.
        
        De même, la ligne d'une matrice est le vecteur/la famille $\bsL_i\p{M} = \p{a_{i, j}}_{j \in \iint{1, m}} = \p{a_{i, j}}_j$
    \end{definition}
    
    On a $\intc{A}_{i, j} = a_{i, j}$.
    
    \subsection{Opérations}
    
    $A + B$ : $\intc{A + B}_{i, j} = \intc{A}_{i, j} + \intc{B}_{i, j}$.
    
    $\lambda A$ : $\intc{\lambda A}_{i, j} = \lambda \intc{A}_{i, j}$
    
    $A \times B$ : $\intc{AB}_{i, k} = \displaystyle \sum_{j} a_{i, j} b_{j, k}$
    
    $\mtrans{A} = \ens{a_{i, j}}_{j, i}$.
    
    $\Tr A = \displaystyle \sum_{i} a_{i, i}$
    
    \subsection{Propriétés}
    
    $\bcM_{n, m}\p{\bdK}$ est un ev de dimenion $n \times m$.
    
    base canonique $E_{i, j}$ avec $\p{i, j} \in \iint{1, n} \times \iint{1, m}$. %dessin avec la matrice
    
    $E_{i, j} = \p{\delta_{u, i}\delta_{v, j}}_{u, v}$
    
    Sur le produit $\begin{array}{rcl}
        \bcM_{n, m}\p{\bdK} \times \bcM_{m, p}\p{\bdK} &\to& \bcM_{n, p}\p{\bdK}  \\
        A, b &\mapsto AB 
    \end{array}$, on a :
    
    \begin{enumerate}
        \itt associativé : $\p{AB}C = A\p{BC}$
        
        \itt $E_{i, j}E_{j', k} = E_{i, k}\delta_{j, j'}$
    \end{enumerate}
    
    $A \mapsto \mtrans{A}$ linéaire et involutive.
    
    $\mtrans{\p{AB}} = \mtrans{A}\mtrans{B}$
    
    $\Tr{AB} = \Tr{BA}$.
    
    \subsection{Application linéaire associée à une matrice}
    
    
    \begin{enumerate}
        \itt $\bdK^n = \bcM_{n, 1}\p{\bdK}$
        
        \itt $\bcM_{n, m}\p{\bdK}$ agit sur $\bdK^m$
        
        \itt $AX = Y \in \bdK^n$ et $u_A = \begin{array}[t]{rcl}
            K^m &\to& K^n  \\
            X &\mapsto& AX 
        \end{array}$
    \end{enumerate}
    
    \subsection{Matrice par blocs}
    
    On peut écrire $\begin{pNiceMatrix}
        A & B\\
        C & D
    \end{pNiceMatrix}\begin{pNiceMatrix}
        X
        Y
    \end{pNiceMatrix} = \begin{pNiceMatrix}
        AX + BY\\
        CX + DY
        \end{pNiceMatrix}$.
        
    Ceci se généralise :
    
    %\begin{pNiceMatrix}
    %
    %\end{pNiceMatrix}
    
    \[ \begin{pNiceMatrix}
            A & B\\
            C & D
        \end{pNiceMatrix}\begin{pNiceMatrix}
            X & Y\\
            Z & T
        \end{pNiceMatrix} =
        \begin{pNiceMatrix}
            AX + BZ & AY + BT\\
            CX + DZ & CY + DT
        \end{pNiceMatrix}\]
        
    
    Soit $M = \begin{pNiceMatrix}
        A & B\\
        C & D
    \end{pNiceMatrix}$. On a $\mtrans{M} = M \iff \begin{pNiceMatrix}
            \mtrans{A} & \mtrans{C}\\
            \mtrans{B} & \mtrans{D}
        \end{pNiceMatrix} = M \iff A, D$ symétriques et $B = \mtrans{C}$.
        
    \section{Applications linéaires et matrices}
    
    \subsection{Définitions}
    
    $A$ agit $K^m \to K^n$. $u \in \bcL\p{E, F}$. $\bcB$ base de $E$ et $\bcC$ de $F$. On a $\bcB = \p{e_j}_j$ et $\bcC = \p{f_i}_i$.
    
    $A = \Mat_{\bcB, \bcC} u = \p{a_{i, j}}_{i, j}$
    
    \subsection{Isomorphisme $\bcL\p{E, F} \cong \bcM_{n, m}\p{\bdK}$}
    
    isomorphisme, démo : lin puis dim puis inj
    
    \subsection{Matrices et produit / composition}
    
    $\begin{array}{ccccc}
        E &\to& F &\to& G  \\
        \bcB & u& \bcC & v& \bcD 
    \end{array}$ et $\Mat_{\bcB, D}\p{v \circ u} = \Mat_{\bcC, \bcD}\p{v} \times \Mat_{\bcB, \bcC}\p{u}$
    
    \subsection{Changement de bases}
    
    Révisions sur le changement de base
    
    \subsection{Théorème fondamental en en trois versions}
    
    \begin{enumerate}
        \item     $s$ supplémentaire de $\Ker u$ $\begin{array}{rcl}
        S &\to& \Imm u  \\
        x &\mapsto& u\p{x} 
    \end{array}$
    
    \item $\exists \bcB, \bcC$ bases de $E$ et $F$ tel que $\Mat_{\bcB, \bcC}\p{u} = \begin{pNiceMatrix}
        I_r & 0\\
        0 & 0
    \end{pNiceMatrix}$ où $r = \rg u$.
    
    \item $u, v \in \bcL\p{E, F}$. $v$ et $u$ sont dites équivalentes s'il existe deux isomorphismes $\varphi$ et $\psi$ tels que $v = \varphi u \psi$. C'est une relation d'équivalences.
    
    \end{enumerate}
    
    \section{Dualité en dimension finie}
    
    def : Soit $E$ un $\bbK$-ev, $f$ une forme linéaire sur $E$ est : $f : E \to \bbK$.
    
    On appelle dual l'ensemble $E^* = \bcL\p{E, \bbK}$ des formes linéaires.
    
    \newpage
    
    Soit $H$ un hyperplan d'un $\bbK$ espace vectoriel $E$ de dimension finie. Quelles sont les formes linéaires $E^*$ telles que $H = $
    
    \newpage
    
    Soit $D = \begin{vNiceMatrix}
        1 & 0 & 1 & 0 & 0\\
        x & 1 x & y & 1 & 0\\
        x^2 & 2x & y^2 & 2y & 2\\
        x^3 & 3x^2 & y^3 & 3y^2 & 6y\\
        x^4 & 4x^3 & y^4 & 4y^3 & 12y^2
    \end{vNiceMatrix}$. Montrer que $D$ est nul si et seulement si $x = y$.
    
    \vspace{5cm}
    
    \begin{exercise}{}{}
        Soit $\p{\varphi_i}_{i \in \iint{1, k}}$ des formes linéaires de $E$. Montrer que $\p{\varphi_i}_{i \in \iint{1, k}}$ est libre si et seulement si l'application $F : \begin{array}[t]{rcl}
            E &\to & \bbK^k  \\
            x &\mapsto& \p{\varphi_i \p{x}}_{i \in \iint{1, k}}
        \end{array}$ est surjective.
        
        \tcbline
    
    
        On a $\Imm F = \ens{\p{\varphi_1\p{x}, \dots \varphi_k\p{x}}, x \in E} \subset \bbK^k$. Si $F$ est non surjective, alors $\Imm F$ est sev strict de $\bbK^k$.
    
        On considère donc $H$ un hyperplan de $\bbK^k$ tel que $\Imm F \subset H$. On a alors $H = \Ker \phi$ où $\phi \in \p{\bbK^k}^\star$. 
        
        Or $\p{K^k}^\star \cong \bbK^k$, ainsi il existe $\p{a_i}_{i \in \iint{1, k}} \in \bbK^k$ tel que $H = \ens{\p{y_i}_{i \in \iint{1, k}} \enstq \displaystyle\sum_{i=1}^k a_iy_i = 0}$.
        
        Puisque $\Imm F \subset H$, on a donc : \qquad $\displaystyle\forall x \in E,\quad \sum_{i=1}^k a_i\varphi_i\p{x} = 0$.
        
        
        Si $F$ est surjective, alors  il existe $e_i$ tel que $\varphi_j\p{e_i} = \delta_{ij}$.
        
        Si $\displaystyle\sum \lambda_i \varphi_i = 0$, alors avec $e_j$ on obtient $\lambda_j e_j = 0$ d'où $\lambda = 0$.
    \end{exercise}
    
    
    \chapter{Calcul pratique sur les matrices}
    
    \chaptertoc
    
    \section{Opérations élémentaires}
    
    \subsection{Définition}
    
    \begin{definition}{Transvection}{}
        La matrice de transvection est $T_{ij}\p{\lambda} = I_n + \lambda E_{i, j}$ avec $i \neq j$ :
        %
        \[ \hg{\begin{pNiceMatrix}
            1 & & \lambda \\
             & \Ddots & \\
             & & 1
        \end{pNiceMatrix}}\]
    \end{definition}
    
    \begin{definition}{Dilatation}{}
        La matrice de dilatation est $D_i\p{\lambda} = I_n + \p{\lambda - 1}E_{i, i}$ avec $\lambda \neq 0$ :
        %
        \[ \hg{\begin{pNiceMatrix}
            1 & & (0) \\
             & \lambda & \\
            (0) & & 1
        \end{pNiceMatrix}}\]
    \end{definition}
    
    \begin{definition}{Permutatition}{}
        La matrice de permutation de $\sigma \in \bfS$ est $P_{\sigma}$ tel que $\intc{P_\sigma}_{i, j} = \delta_{i, \sigma{j}}$
        %
        \[ \hg{\begin{pNiceMatrix}
             & &  \\
             & \intc{P}_{\sigma\p{j}, j} = 1 & \\
             & & 
        \end{pNiceMatrix}}\]
    \end{definition}
    
    \subsection{Propriétés}
    
    \begin{property}{}{}
        \begin{enumerate}
            \itast $T_{ij}\p{\lambda}T_{ij}\p{\mu} = T_{ij}\p{\lambda + \mu}$
            
            \itast $T_{ij}\p{\lambda}^{-1} = T_{ij}\p{-\lambda}$
            
            \itast $D_i\p{\lambda}D_i{\mu} = D_i\p{\lambda\mu}$
            
            \itast $D_i\p{\lambda}^{-1} = D_i{\lambda^{-1}}$
            
            \itast $P_\sigma P_\tau = P_{\sigma\tau}$
        \end{enumerate}
    \end{property}
    
    \subsection{Effet sur une matrice}
    
    \subsubsection{Effet à droite}
    
    \begin{enumerate}
        \itt $T_{ij}\p{e_k} = e_k$ pour $k \neq j$
        
        \itt ...
    \end{enumerate}
    
    \subsubsection{Effet à gauche}
    
     Etc etc
    
    \section{Calcul pratique}
    
    \subsection{Rang}
    
    Le rang est invariant par opération sur les colonnes. De plus, avec :
    %
    \[ A = \begin{pNiceMatrix}
        \lambda_1 & & \star\\
        & \Ddots & \\
        (0) & & \lambda_n
    \end{pNiceMatrix}\]
    %
    On a $\rg_{A} = n$ si et seulement si $\lambda_i \neq 0$ pour tout $i \in \iint{1, n}$.
    
    Il n'y a cependant aucun lien entre $\rg_{A}$ et $\Card \ens{i \enstq \lambda_i = 0}$. Contre exemple :
    %
    \[ \begin{pNiceMatrix}
        0 & 1 &   &  & \star\\
          & 0 & 1 &  & \\
          &   & \Ddots & \Ddots & \\
          &   &   &  & 1\\
        (0)  &   &   &  & 0
    \end{pNiceMatrix}\]
    
    \subsection{Déterminant}
    
    On peut opérer sur lignes et colonnes. Attention, $\det D_i\p{\lambda} = \lambda$ et $\det P_\sigma = \epsilon\p{\sigma}$.
    
    \subsection{Inversion}
    
    Si $\theta_1, \dots, \theta_n$ tq $A \theta \dots \theta_n = I_n$, alors $A^{-1} = \theta_1\dots\theta_n$. 
    
    \begin{align*}
        \p{\begin{array}{ccc|ccc}
            1 & 1 & 1 & 1 & 0 & 0  \\
            -1 & 2 & 1 & 0 & 1 & 0 \\
            1 & 1 & 0 & 0 & 0 & 1
        \end{array}} &\iff \p{\begin{array}{ccc|ccc}
            1 & 1 & 1 & 1 & 0 & 0  \\
            0 & 3 & 2 & 1 & 1 & 0 \\
            0 & 0 & -1 & -1 & 0 & 1
        \end{array}}\\
        &\iff \p{\begin{array}{ccc|ccc}
            1 & 1 & 0 & 0 & 0 & 1  \\
            0 & 3 & 0 & -1 & 1 & 2 \\
            0 & 0 & -1 & -1 & 0 & 1
        \end{array}}\\
        &\iff \p{\begin{array}{ccc|ccc}
            1 & 1 & 0 & 0 & 0 & 1  \\
            0 & 1 & 0 & -\sfrac{1}{3} & \sfrac{1}{3} & \sfrac{2}{3} \\
            0 & 0 & 1 & 1 & 0 & -1
        \end{array}}\\
        &\iff \p{\begin{array}{ccc|ccc}
            1 & 0 & 0 & -\sfrac{1}{3} & -\sfrac{1}{3} & -\sfrac{1}{3}   \\
            0 & 1 & 0 & -\sfrac{1}{3} & \sfrac{1}{3} & \sfrac{2}{3} \\
            0 & 0 & 1 & 1 & 0 & -1
        \end{array}}
    \end{align*}
    
    \chapter{Déterminants}
    
    On a vu l'année dernière que les déterminants étaient un critère numérique d'inversibilité très important et utile. On a par ailleurs vu que $\det{AB} = \det A \det B$.
    
    \chaptertoc
    
    \section{Calcul multilinéaire}
    
    \subsection{Définition}
    
    \begin{definition}{Application multilinéaire}{}
        Soit $n \in \bdN$, une collection $\p{E_i}_{i \in \iint{1, n}}$ de $\bbK$-espaces vectoriels et $F$ un $\bbK$-espace vectoriel. On dit d'une fonction $f : E_1 \times \dots \times E_n \to F \in \bcF\p{\displaystyle\prod_{i=1}^n E_i, F}$ qu'elle est $n$ linéaire lorsque :
        %
        \[ \forall \p{x_i}_{i \in \iint{1, n}} \in \prod_{i=1}^n E_i,\qquad \forall i \in \iint{1, n},\qquad f_i : \begin{array}[t]{rcl}
            E_i &\to& F  \\
            y &\mapsto& f\p{x_1, \dots, x_{i-1}, y, x_{i+1}, \dots x_n}
        \end{array} \in \bcL\p{E_i, F}\]
    \end{definition}
    
    \begin{example}{}{}
        \begin{enumerate}
            \item Si $f$ est linéaire, $f\p{0, \dots, 0} = 0$. Si $f$ $n$-linéaire, alors $f\p{\bullet, \dots, \bullet, 0, \bullet \dots, \bullet} = 0$.
            
             \item linéaire en $x$ :  homogène degré $1$ des coordonnées de $x$
             
             $n$-linéaire en $\p{x_1, \dots, x_n}$ : homogène de degré $n$ des coordonnées des $x_i$
             
             \item $\p{x, y} \mapsto x + y$ est linéaire.
             
             $\p{x, y} \mapsto xy$ est bilinéaire.
        \end{enumerate}
    \end{example}
    
    \begin{definition}{Forme multilinéaire}{}
        $f : E_1 \times \dots \times E_n \to \bbK$ forme $n$-linéaire.
    \end{definition}
    
    \subsection{Cas de la dimension finie}
    
    Prenons $n \in \bdN$ et une collection $\p{E_i}_{i \in \iint{1, n}}$ de $\bbK$-espaces vectoriels de dimension finie. Pour tout $j \in \iiint{1, n}$, on considère $E_j$ de dimension $d_j = \dim E_j$ et une base $\bcB_j = \p{e_{j, 1}, e_{j, 2}, \dots, e_{j, d_j}}$. Pour un $n$-uplet $\p{x_1, \dots, x_n}$ on a alors :
    %
    \[ x_j = \sum_{i=1}^{d_j} \lambda_{1, j}e_{1, j}\]
    
    \subsection{Formes alternées, antisymétriques}
    
    Definitions [...]
    
    Prop : antisymétrique $\iff$ alternée (si $\bbK \subset \bdC$ et que la caractéristique de $\bbK$ n'est pas égale à $2$).
    
    Soit $f$ une forme antisymétriques. On a $f\p{x_{\sigma\p{1}}, \dots, x_{\sigma\p{n}}} = \epsilon\p{\sigma}f\p{x_1, \dots, x_n}$.
    
    Action de groupe : $\bfS_n$ agit sur $E^n$ par $\sigma x = \p{x_{\sigma\p{1}}, \dots, x_{\sigma\p{n}}}$, $1 x = x$ et $\sigma\p{\tau x} = \p{\sigma \tau} x$
    
    \section{Déterminants}
    
    \subsection{Déterminant d'une famille}
    
    Il existe une unique forme $n$-linéaire alternée $f$ sur $E$ de dimension $n$ tel que $f\p{\bcB} = 1$ . On note $f = \det_\bcB$.
    
    Par propriété de changement de base ($\bcB$, $\bcC$ deux bases)
    
    \subsection{Matrices par blocs}
    
    Prop : $\begin{vNiceMatrix}
        A & 0\\
        0 & B
    \end{vNiceMatrix} = \mod{A}\mod{B}$
    
    Soit $E$ de dimension $n$ et $F$ de dimension $M$, $\bcB_E$ une base de $E$ et $\bcB_F$ une base de $F$. On considère :
    %
    \[ f : \begin{array}{rcl}
        E^n \times F^m &\to& \bbK  \\
         &\mapsto &
    \end{array}\]
    
    Fixons $x = \p{x_1, \dots, x_n}$
    
    \section{Formules de Cramer}
    
    Formules de \textsc{Cramer}
    
    \subsection{Développement d'un déterminant selon ligne / colonne}
    
    A \quad $n \times n$ \quad $A = \p{a_{i, j}}_{i, j}$
    
    $\Delta_{i, j} = \det$ obtenu en supprimant $\bsL_i$ et $\bsC_j$.
    
    
    \boxans{
            On pose pour $n \in \bdN^*$ la matrice $D_n = \begin{pNiceMatrix}
                    a       &   c       &   0       &   \Cdots  &   0       \\
                    b       &   \Ddots  &  \Ddots   &   \Ddots  &   \Vdots  \\
                    0       &   \Ddots  &           &           &   0       \\
                    \Vdots  &   \Ddots  &  \Ddots   &           &   c       \\
                    0       &   \Cdots &0\phantom{-}&   b       &   a
                \end{pNiceMatrix}_{\left[n\right]}$. On développe $\det{D_n}$ selon la ligne 1 :
                %
                \[ \det{D_n} = \sum_{j=1}^n \p{-1}^{1+j}\left[D_n\right]_{1, j}\Delta_{1,j}\p{D_n} = a\begin{vNiceMatrix}
                    a       &   c       &   0       &   \Cdots  &   0       \\
                    b       &   \Ddots  &  \Ddots   &   \Ddots  &   \Vdots  \\
                    0       &   \Ddots  &           &           &   0       \\
                    \Vdots  &   \Ddots  &  \Ddots   &           &   c       \\
                    0       &   \Cdots &0\phantom{-}&   b       &   a
                \end{vNiceMatrix}_{\left[n-1\right]} -c \begin{vNiceMatrix}
                    b       &   c       &   0       &   \Cdots  &   0       \\
                    0       &   a       &  \Ddots   &   \Ddots  &   \Vdots  \\
                    \Vdots  &   b       &  \Ddots   &           &   0       \\
                            &   0       &  \Ddots   &           &   c       \\
                            &   \Vdots  &  \Ddots   &           &   a        \\
                    0       &   0       &   \Cdots  &0\hphantom{--}&   b\vphantom{\dfrac{-}{-}}
                \end{vNiceMatrix}_{\left[n-1\right]}\]
                %
                On reconnaît le premier terme comme étant $\det{D_{n-1}}$. En développant le second terme selon la première colonne, on reconnaît également $b\det{D_{n-2}}$. On a donc pour entier $n \in \bdN$ tel que $n \geq 3$, $\det{D_n} = a\det{D_{n-1}} - bc\det{D_{n-2}}$.
        }
        
        \boxans{
            On pose pour $n \in \bdN^*$ la matrice 
        }
        
 \chapter{Groupes finis}
 
 exercice :
 %
 On a le polynôme cyclotomique, où $\zeta_k^n = \exp{2\ii\dfrac{k\pi}{n}}$
 %
 \[ \phi_n = \prod_{k \in \p{\sfrac{\bdZ}{n\bdZ}}^\star} \p{X - \zeta_k^n}\]
 %
 \begin{enumerate}
     \itt Montrer que $\displaystyle\prod_{d \mid n} \phi_d = X^n - 1$
     
     \boxans{
        Montrons d'abord que les inversibles de $\sfrac{\bdZ}{n\bdZ}$ sont les entiers premiers avec $n$ :
        %
        \begin{enumerate}
            \itt $\boxed{\implies}$ Soit $\overline{a} \in \sfrac{\bdZ}{n\bdZ}$ tel que $\pgcd\p{a, n} = 1$. Par \textit{théorème de Bézout}, on a :
            %
            \[ \exists \p{u, v} \in \bdZ^2 \qquad au + nv = 1 \qquad\text{donc}\qquad au = 1 -nv \qquad\text{donc}\qquad \overline{a}\,\overline{u} = 1 \]
            %
            Donc $\overline{a}$ est inversible.
            
            \itt $\boxed{\impliedby}$ Supposons que $\overline{a}$ est inversible d'inverse $\overline{u}$. Même raisonnement dans le sens inverse.
        \end{enumerate}
        %
        On pose $\psi = X^n - 1$ et $\zeta = \zeta_1^n$. Les racines de $\psi$ sont exactement les racines $n$-ièmes de l'unité (les éléments de $\bdU_n$), \ie les $\p{\zeta_k^n = \zeta^k}_{k \in \iint{0, n-1}}$. Ainsi, $\psi = X^n - 1 = \displaystyle\prod_{k=0}^{n-1} \p{X - \zeta^k}$.
        
        Les $\p{\zeta^k}_{k \in \iint{0, n}}$ sont des éléments du groupe multiplicatif $\p{\bdU_n, \times}$, donc on peut les trier selon leur ordre.
        
        Soit $d \mid n$, il existe $m \in \iint{1, n}$ minimal tel que $n = md$. Soit $k \in \iint{0, n-1}$ tel que $\mod{\langle \zeta_k\rangle} = d$.
        
        Par \textit{théorème de Lagrange}, on a $d \mid n$, dès lors :
        %
        \[ X^n - 1 = \prod_{d \mid n} \prod_{\substack{k = 0\\ \mod{\langle\zeta^k\rangle} = n}}^d\p{X - \zeta^k} \qquad\text{donc montrons que}\qquad \prod_{\substack{k = 0\\ \mod{\langle\zeta^k\rangle} = n}}^d\p{X - \zeta^k} = \phi_d = \prod_{\ell \in \p{\sfrac{\bdZ}{d\bdZ}}^\star} \p{Z - \zeta_\ell^d}\]
        %
         L'ordre de $\zeta^k$ étant le plus petit entier $d \in \bdN^*$ tel que ${\zeta^k}^d = 1$, d'où $\zeta^k \in \bdU_d$. Ainsi il existe $\ell \in \iint{0, d-1}$ tel que $\zeta^k = \zeta_\ell^d$. Donc $\p{\zeta_\ell^d}^{d} = 1$ d'où $\p{\zeta_\ell^d}\p{\zeta_\ell^d}^{d-1} = 1$
        %
        \[ \zeta_\ell^d = \zeta_k^n \qquad\text{d'où}\qquad \dfrac{\ell}{d} = \dfrac{k}{n} \qquad\text{donc}\qquad \dfrac{\ell m}{n} = \dfrac{k}{n} \qquad\text{donc}\qquad \ell m = k\]
        %
        Or $k $
        %
        
        %
        Ainsi toute racine de $\phi_d$ est dans $\bdU_n$, \ie toute racine de $\phi_d$ est racine de $X^n -1$. Ainsi $\psi \mid X^n - 1$. Or :
        %
        \[ \deg\p{\psi} = \deg\p{\displaystyle\prod_{d \mid n} \phi_d} = \sum_{d \mid n}\deg\p{\phi_d} = \sum_{d \mid n} \varphi\p{d}\]
        %
        Il s'agit donc de montrer que $\displaystyle \sum_{d \mid n} \varphi\p{d} = n$. On peut penser à un partitionnement selon les diviseurs de $n$.
        
        On remarque d'une part que $\p{\bdZ/d\bdZ}^\star$ possède exactement $\varphi\p{d}$ générateurs. On peut donc essayer de partitionner $\bdZ/n\bdZ$ en des groupes isomorphes aux $\p{\bdZ/d\bdZ}^\star$ où $d \mid n$. Il s'agit donc d'exhiber une partiton de groupes multiplicatifs de cardinal $d$ dans $\bdZ/n\bdZ$
        
        On remarque qu'on a $m$ tel que $m = \sfrac{n}{d}$. Donc $\phyavg{m} = \ens{0, m, 2m, \dots, \p{d-1}m}$ (sous-groupe de $\bdZ/n\bdZ$)  est de cardinal $\sfrac{n}{m} = d$.
        %On peut donc écrire le résultat suivant :
        %
        %\[ \phi_n = \prod_{k < n \ \pgcd\p{k, n} = 1} \p{X - \zeta_k^n} \qquad\text{d'où}\qquad \prod_{d \mid n} \phi_d\]
     }
     
     
     \itt En déduire que $\phi_n \in \bdZ\intc{X}$
     
     \itt Dificile. Montrer que $\phi_n$ est irréductible sur $\bdZ$.
 \end{enumerate}
 
    \chapter{Réduction des endomorphismes}
    
    Intro
    
    \chaptertoc
    
    \section{Généralités}
    
    \subsection{Contexe}
    
    On considère dans ce chapitre un corps $\bbK$  (on pourrait prendre $\bdR$ ou $\bdC$, même $\bbK \subset \bdC$, mais on prendra ici $\bbK$ quelconque).
    On considère $E$ un $\bbK$-espace vectoriel (qui sera généralement de dimension finie) et une application linéaire $u \in \bcL\p{E}$.
    
    On commence par définir la notion de vecteur propre : il s'agit d'un vecteur non nul sur lequel $u$ agit comme une homothétie :
    %
    \begin{definition}{Vecteur et valeur propre}{}
        On dit que $x \in E$ est un vecteur propre si et seulement si $x \neq 0$ et $\exists \lambda \in \bbK$ tel que $u\p{x} = \lambda x$.
        
        On dit que $\lambda \in \bdK$ est une valeur propre si $\exists x \in E$, $x \neq 0$ tel que $u\p{x} = \lambda x$.
        
        La valeur propre et le vecteur propre sont dit associés.
    \end{definition}
    %
    \begin{notation}
        Une valeur propre sera noté $v_p$, un vecteur propre associé $\vec{v_p}$ et inversement.
    \end{notation}
    
    \begin{definition}{Spectre}
        L'ensemble des valeurs propres de $u$ est appelé spectre de $u$.
    \end{definition}
    
    \begin{notation}
        Le spectre de $u$ est noté $\Sp{u}$
    \end{notation}
    
    \begin{definition}{Polynôme caractéristique}{}
        Le polynôme caractéristique de $u$ est $\chi_u\p{X} = \det{u - X\Id}$
    \end{definition}
    
    
    exemple : $u \in \Sp{u} \iff \exists x \in E,\quad x \neq 0,\quad u\p{x} = 0\iff u \ \text{non inversible et non injective}$
    
    \subsection{Propriétés}
    
    \begin{property}{}{}
        \[ \lambda \in \Sp{u} \iff \chi_u\p{\lambda} = 0\]
    \end{property}
    %
    \begin{nproof}
        \[ \lambda \ \text{est une valeur propre} \iff \exists x \neq 0,\quad u\p{x} = \lambda x \quad \p{u - \lambda \Id} \ \text{non inversible} \iff \det{u - \lambda \Id} = 0\]
    \end{nproof}
    
    \begin{property}{}{}
        Les valeurs propres sont les racines du polynôme caractéristique.
    \end{property}
    
    \begin{definition}{Sous-espace vectoriel propre}{}
        \[ E_\lambda = \ens{x \in E \enstq u\p{x} = \lambda x} = \Ker{u - \lambda \Id}\]
        %
        sous-espace vectoriel propre associé à $\lambda$
    \end{definition}
    
    \section{Action de $\bdK$[X]}
    
    \subsection{Définitions}
    
    $P = \sum_i a_iX^i \in \bdK\intc{X}$.
    
    Soit $u \in \bcL\p{E}$, que dire de $P\p{u}$ ?
    
    $u^0 = \Id$ et $u^{n+1} = u^n u = uu^n$ (assoc.)
    
    $P\p{u} = \sum_i a_iu^i$.
    
    ex : $\p{1 + X^2}\p{u} = \id + u^2 \neq 1 + u^2$.
    
    ex : $P\p{u} \in \bcL\p{E}$ agit sur $E$ par $\p{P\p{u}}\p{x} \in E$ où $x \in E$ avec $\p{P\p{u}}\p{x} = P\p{u}\p{x}$.
    
    Donc $\p{\p{1 + X^2}\p{u}}\p{X} = \p{\Id + u^2}\p{x} = x + u^2\p{x} = x + u\p{u\p{x}}$.
    
    \subsection{Propriétés}
    
    $\begin{array}[t]{rcl}
        \bdK\intc{X} &\to& \bcL\p{E}  \\
        P &\mapsto& P\p{u} 
    \end{array}$ est un morphisme d'algèbres .
    
    Preuve : lin, $\p{PQ}\p{u} = P\p{u}Q\p{u}$, image du neutre $1\p{u} = \Id$
    
    demo : $P = \sum a_iX^i$ et $Q =\sum b_iX^i$
    
    Donc $\lambda P Q = \sum \p{\lambda a_i + \mu b_i}X^i$, on pousse la craie, ok.
    
    Produit : 1ère rédac,$P = \sum a_iX^i$ et $Q =\sum b_iX^i$, donc $PQ = \sum c_kX^k$ avec $c_k = \sum_{i+j = k} a_ib_j$. On pousse la craie, ok.
    
    2ème rédac, par bilinéarité de $\p{P, Q} \mapsto \p{PQ}\p{u}$, testant une base. Voir $u^iu^j = u^{i+j}$ (assoc.).
    
    \subsection{Rappels arithmétique de $\bdK$[X]}
    
    Notion de poly irréductible sur $\bdK$ (pas de diviseur non trivial)
    
    ex : irred sur $\bdC$, degré de $P = 1$ ; irred sur $\bdR$, degré de $P = 1$ ou $2$ avec $\Delta < 0$.
    
    Sur $\bdQ$ ??? il y a red irred de degré quelconque.
    
    ex $X^4 + 1$ irred sur $\bdR$ ? (non évidemment).
    
    Pour cela, $X^4 + 1 = \p{X^2 + 1}^2 - 2X^2 = \p{X^2 + 1 - \sqrt{2}X}\p{X^2 + 1 + \sqrt{2}X}$.
    
    Facorialité : tout poly s'écrit comme produit d'irreductibles unicité à l'ordre près et aux constantes multiplicatives près sur les irred.
    
    $P, Q$ dits premirs entre si sans facteur commun ; PGCD.
    
    Th de Gauss : $P \mid QR$ avec $\pgcd{P, Q} = 1$ implique $P \mid R$ 
    
    Th de Bezout : $\pgcd{P, Q} = 1$ ssi $\exists U, V \quad UP + VQ = 1$.
    
    Idéaux de $\bdK\intc{X}$, $I$ idéal si sous groupe pour $+$ et stable par multiplication externe à $I$.
    
    \subsection{Lemme des noyaux}
    
    Théorème de décomposition des noyaux
    
    Prop : si $\pgcd\p{P, Q} = 1$, alors $\Ker\p{PQ}\p{u} = \Ker P\p{u} \oplus \Ker Q\p{u}$
    
    Si $P_1, \dots, P_k$ deux à deux premiers entre eux, alors $\Ker\p{P_1 \dots P_k}\p{u} = \bigoplus_{i=1}^k \Ker P_i\p{u}$.
    
    Démo : $\pgcd{P, Q} = 1$.
    
    $UP + VQ = 1 \iff U\p{u}P\p{u} + V\p{u}Q\p{u} = \Id \iff U\p{u}\p{P\p{u}\p{x}} + V\p{u}\p{Q\p{u}\p{x}} = x$ avec $x \in E$.
    
    \begin{enumerate}
        \itt $\oplus$ : $x \in \Ker P\p{u} \cap \Ker Q\p{u}$, on a :
        %
        $P\p{u}\p{x} = 0$ et $Q\p{u}\p{x} = 0$ soit $U\p{u}P\p{u}\p{x} = 0$ et $V\p{u}Q\p{u}\p{x} = 0$.
        
        \itt $+$, et $x = 0$.
        %
        On a $x \in \Ker PQ\p{u}$ et $P\p{u}Q\p{u}\p{x} = 0$. Avec :
        %
        \[ x = \underbrace{U\p{u}P\p{u}\p{x}}_{x'} + \underbrace{V\p{u}Q\p{u}\p{x}}_{x''}\]
        %
        Avec $x' \in \Ker Q\p{u}$ : $Q\p{u}\p{x'} = Q\p{u}U\p{u}P\p{u}\p{x} = UPQ\p{u}\p{x} = U\p{u}\p{PQ\p{u}\p{x}} = 0$.
        
        Et $x'' \in \Ker P\p{u}$ : $P\p{u}\p{x''} = PVQ\p{u}\p{x} = V\p{u}\p{\p{PQ}\p{u}\p{x}} = 0$.
        
        
    \end{enumerate}
    
    On prend $M = \begin{pNiceMatrix}
        A & A\\
        0 & A
    \end{pNiceMatrix}$. CNS de diag.
    
    Calculons $M^k$. On a $M^2 = \begin{pNiceMatrix}
        A^2 & 2A^2\\
        0 & A^2
    \end{pNiceMatrix}$, $M^3 = \begin{pNiceMatrix}
        A^3 & 3A^3\\
        0 & A^3
    \end{pNiceMatrix}$ et généralement $M^k = \begin{pNiceMatrix}
        A^k & kA^k\\
        0 & A^k
    \end{pNiceMatrix}$. On a donc globalement $P\p{M} = \begin{pNiceMatrix}
        P\p{A} & AP'\p{A}\\
        0 & P\p{A}
    \end{pNiceMatrix}$.
    
    
    
    
    \newpage
    
    \begin{exercise}{462 - TD $\star$}{}
        Soit $A \in \bcM_n\p{\bdK}$. Montrer l'équivalence entre $A^2 = 0$ et
        $A$ est semblable à $\begin{pNiceMatrix}
            0 & I_r\\
            0 & 0\\
        \end{pNiceMatrix}$ avec $2r \leq n$.
        %
        \tcbline
        
        Si $A$ est semblable à une telle matrice, on vérifie facilement que $A^2 = 0$. 
        
        Dans le cas réciproque, soit $A$ tel que $A^2 = 0$. Donc $\Im A \subset \Ker A$, d'où par théorème du rang, en posant $r = \rg A$ on a $2r \leq n$. On considère une base $\p{e_1, e_2, \dots, e_r}$ de l'image, que l'on complète en une base $\p{e_1, e_2, \dots, e_{n-r}}$ du noyau. On considère un antécédent $u_1$ de $e_1$. $u_1$ n'est pas dans le noyau car $e_1$ n'est pas nul, donc il est linéairement indépendant des $e_1, \dots, e_{n-r}$. On réitère le procédé, et on génère $u_1, u_r$ vecteurs. La famille $\bcB = \p{e_1, \dots, e_{n-r}, u_1, e_r}$ est libre et par dimension, elle est une base de $E$. Or $\Mat_\bcB A = U$.
    \end{exercise}

    \chapter{Topologie}
    
    Le but de la topologie est d'étudier les \emph{proximités}. Ce chapitre a plusieurs objectifs :
    %
    \begin{enumerate}
        \itt Premier objectif : comprendre continuité, la convergence en dimension finie
        
        \itt Deuxième objectif : assimiler les notions nouvelles d'ouverts, de fermés, de compact, de valeur d'adhérence, etc
        
        \itt Troisième objectif : comprendre la topologie au service des mathématiques.
    \end{enumerate}
    
    \chaptertoc
    
    \section{Normes}
    
    Dans toute la suite de ce corps, on considérera un corps $\bdK$ tel que $\bdK = \bdR$ ou $\bdK = \bdC$, et $E$ un $\bdK$-espace vectoriel.
    
    \subsection{Définition}
    
    \begin{definition}{Norme}{}
        On appelle \hg{norme} un application $N : E \to \bdR_+$ telle que pour tout $x \in E$, on a 
        \begin{enumerate}
            \itast $N\p{x} \geq 0$ (positivté)
            \itast $N\p{x} = 0 \implies x = 0$ (séparation)
            \itast Pour tout scalaire $\lambda \in \bdK$, $N\p{\lambda x} = \mod{\lambda} N\p{x}$ (homogénéité).
            \itast Pour tout vecteur $y \in E$, $N\p{x + y} \leq N\p{x} + N\p{y}$ (inégalité triangulaire).
        \end{enumerate}
    \end{definition}
    
    \begin{property}{Inégalité triangulaire}{}
        \[ \hg{\mod{N\p{x} - N\p{y}} \leq N\p{x - y}} \]
    \end{property}
    %
    \begin{nproof}
        $N\p{x} = N\p{x - y + y} \leq N\p{x - y} + N\p{y}$. De même $N\p{y} \leq N\p{x - y} + N\p{x}$. On conclut.
    \end{nproof}
    
    \subsection{Exemples classiques}
    
    \begin{example}{Norme sur $\bdR^n$}{}
        \begin{enumerate}
            \itt $\displaystyle N_1\p{X} = \sum \mod{x_i}$
            
            \itt $\displaystyle N_2\p{X} = \sqrt{\sum {x_i}^2}$
            
            \itt $\forall p \geq 1$, $\displaystyle N_p\p{X} = \p{\sum {x_i}^p}^{\sfrac{1}{p}}$
            
            \itt $\displaystyle N_\infty\p{X} = \sup\limits_i\ens{\mod{x_i}}$
        \end{enumerate}
    \end{example}
    
    \begin{example}{Norme sur $\bdC^n$}{}
        \begin{enumerate}
            \itt $\displaystyle \norm{X}_1 = \sum \mod{x_i}$
            
            \itt $\displaystyle \norm{X}_2 = \sqrt{\sum \mod{x_i}^2}$
            
            \itt $\displaystyle \norm{X}_\infty = \sup\limits_i\ens{\mod{x_i}}$
        \end{enumerate}
    \end{example}
    
    \begin{example}{Norme sur $E$ de dimension finie}{}
        Soit $\bcB = \p{e_i}_i$ une base tel que $x = \displaystyle\sum x_ie_i$.
        %
        \begin{enumerate}
            \itt $\displaystyle N_1\p{X} = \sum \mod{x_i}$
            
            \itt $\displaystyle N_2\p{X} = \sqrt{\sum \mod{x_i}^2}$
            
            \itt $\displaystyle N_\infty\p{X} = \sup\limits_i\ens{\mod{x_i}}$
        \end{enumerate}
    \end{example}
    
    \begin{example}{Sur $\bcC\p{\intc{0, 1}, \cdot}$}{}
        Sur $\bcM_{n, m}\p{\bdK}$ il y a d'autres normes. Sur $\bcC^\infty \p{\intc{0, 1}, \bdR}$, on a :
        \begin{enumerate}
            \itt $N_1\p{f} = \displaystyle\int_0^1 \mod{f\p{t}} \dif t$
            
            \itt $N_2\p{f} = \sqrt{\displaystyle\int_0^1 \mod{f\p{t}}^2\dif t}$
            
            \itt $N_\infty\p{f} = \sup\limits_{x \in \intc{0, 1}} \mod{f\p{x}} = \sup\limits_{\intc{0, 1}} \mod{f}$
        \end{enumerate}
        %
        Pour $E$ de dimension finie et $\norm{\cdot}$ une norme sur $E$, sur $\bcC^\infty \p{\intc{0, 1}, E}$ on a :
        %
        \begin{enumerate}
            \itt $N_1\p{f} = \displaystyle\int_0^1 \norm{f\p{t}}\dif t$
            
            \itt $N_2\p{f} = \sqrt{\displaystyle\int_0^1 \norm{f\p{t}}^2\dif t}$
            
            \itt $N_\infty\p{f} = \sup\limits_{x \in \intc{0, 1}} \norm{f\p{x}}$
        \end{enumerate}
    \end{example}
    
    \begin{example}{Des normes moins usuelles}{}
        %
        On peut donner des normes moins usuelles, par exemple sur $\bdK\intc{X}$ :
        %
        \begin{enumerate}
            \itt $\norm{P}_\infty = \sup\limits_{x \in \intc{0, 1}} \mod{P\p{x}}$
            
            \itt $\norm{P}_1 = \displaystyle\int_2^3 \mod{P\p{t}}\dif t$
            
            \itt $\norm{P} = \displaystyle\sum_i i! a_i$
        \end{enumerate}
    \end{example}
    %
    On commence à voir qu'il existe une grande quantité de normes. On peut se rendre compte qu'on peut en fabriquer d'avantage, une fois qu'on en a déjà : sur $\bcC^1\p{\intc{0, 1}, \bdK}$, on considère une norme $N_\infty$ et $N_1$. On remarque par exemple que l'on peut fabriquer les normes suivantes :
    %
    \begin{enumerate}
        \itt $N_1\p{f'} + N_\infty\p{f}$
        \itt $\mod{f\p{0}} + N_\infty\p{f'}$
        \itt $N_\infty\p{f} + N_\infty\p{f'}$
    \end{enumerate}
    
    \subsection{Normes équivalentes}
    
    \begin{definition}{Normes équivlentes}
        Sur $E$, deux normes $N$ et $\norm{\cdot}$ sont dites équivalentes s'il existe $a > 0$ et $A < +\infty$ tel que pour tout $x \in E$ :
        %
        \[ a \norm{x} \leq N\p{x} \leq A\norm{x} \]
        %
    \end{definition}
    %
    Deux normes équivalentes définissent les mêmes notions de proximité.
    %
    \begin{exercise}{}{}
        Comparer les normes précédentes.
    \end{exercise}
    
    On traite le cas dans $\bdR^n$ : $N_1$, $N_2$, $N_\infty$. 
    %
    \begin{enumerate}
        \itt $\displaystyle N_1\p{X} = \sum \mod{x_i}$
            
        \itt $\displaystyle N_2\p{X} = \sqrt{\sum {x_i}^2}$
            
        \itt $\displaystyle N_\infty\p{X} = \sup\limits_i\ens{\mod{x_i}}$
    \end{enumerate}
    %
    Montrons que $N_1$ est une norme :
    %
    \begin{enumerate}
        \itast On a une somme de termes positifs donc positive, d'où la positivité
        
        \itast Si $N_1\p{X} = 0$, alors $\sum \mod{x_i} = 0$ d'où chaque $\mod{x_i} = 0$ d'où $X = 0$
        
        \itast $N_1\p{\lambda X} = \sum \mod{\lambda x_i} = \mod{\lambda} \sum \mod{x_i} = \mod{\lambda} N_1\p{x}$
        
        \itast $N_1\p{X + Y} = \sum \mod{x_i + y_i} \leq \sum \mod{x_i} + \sum \mod{y_i} = N_1\p{X} + N_1\p{Y}$
    \end{enumerate}
    %
    Montrons que $N_\infty$ est une norme :
    %
    \begin{enumerate}
        \itast On a un ensemble de termes positifs donc le sup est positif, d'où la positivité
        
        \itast Si $N_\infty\p{X} = 0$, alors $\sup \ens{x_i} = 0$, or $0 \leq x_i \leq \sup \ens{x_i} = 0$ d'où chaque $\mod{x_i} = 0$ d'où $X = 0$.
        
        \itast $N_\infty\p{\lambda X} = \sup \ens{ \mod{\lambda x_i}} = \mod{\lambda} \sup \ens{\mod{x_i}} = \mod{\lambda} N_\infty\p{x}$
        
        \itast $N_\infty\p{X + Y} = \sup \ens{\mod{x_i + y_i}} \leq \sup \ens{\mod{x_i}} + \sup \ens{\mod{y_i}} = N_\infty\p{X} + N_\infty\p{Y}$
    \end{enumerate}
    
    \section{Topologie}
    
    \subsection{Notion de boule}
    %
    On considère $E$ un $\bdK$-espace vectoriel de norme $\norm{\cdot}$.
    
    \begin{definition}{Boule et sphère}{}
        Soit $a \in E$ et $r \in \bdRp$. On a :
        %
        \begin{enumerate}
            \itt On appelle boule ouverte de centre $a$ et de rayon $r$ l'ensemble $\bcB\p{a, r} = \ens{x, \mod{x - a} < r}$
            
            \itt On appelle boule fermée de centre $a$ et de rayon $r$ l'ensemble $\overline\bcB\p{a, r} = \ens{x, \mod{x - a} \leq r}$
            
            \itt On appelle sphère de centre $a$ et de rayon $r$ l'ensemble $\bcS\p{a, r} = \ens{x, \mod{x - a } < r} = \overline\bcB\p{a, r} \backslash \bcB\p{a, r}$
        \end{enumerate}
    \end{definition}
    %
    \begin{definition}{Voisinage}{}
        $A \subset E$ est un voisinage de $x \in A$ s'il existe $r > 0$ tel que $\bcB\p{x, r} \subset A$
    \end{definition}
    %
    \begin{definition}{Ouvert, fermé}{}
        $O \subset E$ est un ouvert si $O$ est un voisinage de chacun de ses points, \ie
        %
        \begin{enumerate}
            \itast si $\forall a \in O$, $\exists r_a > 0$, $\bcB\p{a, r_a} \subset O$
            
            \itast si $\forall a \in O$, $\exists r_a > 0$, $\norm{x - a} \leq r_a \implies x \in O$.
        \end{enumerate}
        %
        $F \subset E$ est un fermé si $E \backslash A$ est un ouvert.
    \end{definition}
    
    \subsection{TODO}
    
    \subsection{TODO}
    
    \subsection{Caractérisation des fermés}
    
    Prop : $A \subset E$ fermé ssi $A$ stable par passage à la limite, \ie $a_n \in A$ et $a_n \lima a \implies a \in A$ (on ne prétend pas montrer que toute suite converge, on suppose simplement que $a_n$ est convergente).
    
    C'est une caractérisation pratique :
    %
    Si $\complement A$ est ouvert, $a_n \in A$ avec $a_n \lima a$ si $a \not\in A$. On a $a \in \complement A$, donc on a une boule $\bcB\p{a, r} \subset \complement A$. Dès lors $a_n \lima{a}$ : $\norm{a_n - a} < r$ si $n \geq n_0$, donc $a_n \in \bcB\p{a, r} \not\subset A$.
    
    Réciproquement, si $\complement A$ non ouvert, il existe $a \in \complement A$ tq. pour tout $r$, $\bcB\p{a, r} \not\subset A$.
    
    \subsection{Adhérence, intérieur}

    \begin{definition}{Intérieur}{}
        Soit $A$ une partie fixée. On appelle intérieur de $A$ l'ouvert dans lequel tout ouvert de $A$ est inclus :
        %
        \[ \mathring{A} = \mathrm{int}\p{A} = \bigcup_{X \ \text{ouvert} \ \subset A} X\]
        %
        Une deuxième vision consiste à dire qu'un point $a \in A$ est intérieur à $A$ s'il existe $\bcB\p{a, r} \subset A$, \ie si $A$ est voisinage de $A$, ou encore s'il existe une suite telle que $a_n \to a$.
    \end{definition}

    \begin{definition}{Adhérence}{}
        Soit $A$ une partie fixée. On appelle adhérence de $A$ l'intersection des fermés de $A$ : 
        %
        \[ \bar{A} = \mathrm{adh}\p{A} = \bigcap_{F\ \text{fermé}\ \subset A} F \]
        %
        Une deuxième vision consiste à dire qu'un point $a \in A$ est adhérent à $A$ s'il existe une suite $\p{a_n}$ telle que $\p{a_n} \to a$
    \end{definition}
    Pour montrer que $A$ est ouvert, on prend $a \in A$ et on cherche $r$ tel que $\bcB\p{a, r} \subset A$.
    
    Pour montrer que $a$ est intérieur à $A$, on fait de même.
    
    Pour montrer qu'il est non intérieur, on prend une suite de $a_n \not \in A$ telle que $a_n \lima{n \to +\infty} a$.
    
    Pour montrer que $A$ est fermé, on montre la stabilité par passage à la limite :
    %
    \[ a \not\in \overline{A} \qquad \bcB\p{a, r} \subset A = \emptyset\]
    %
    \begin{definition}{Frontière}{}
        \[ \mathrm{Fr}\p{A} = \overline{A} \backslash \mathring{A} = \mathrm{adh}\p{A} \cap \mathrm{adh}\p{E \backslash A}\]
    \end{definition}
    %
    On a bien $a \in \mathrm{Fr}\p{A}$ s'il existe $a_n \in A$ tq $a_n \lima{} a$, s'il existe $b_n \not\in A$ tel que $b_n \lima a$. 
    
    CNS : $\bcB\p{a, r} \cap A \neq\emptyset$ et $\bcB\p{a, r} \cap \complement A \neq \emptyset$.

    \subsection{Topologie relative}
    
    Soit $X$ une partie d'un ouvert.
    
    \begin{definition}{Boule ouverte/fermée relative}{}
        La boule ouverte, respectivement fermée, relativement à  $X$ est 
        \[ \bcB_X\p{a,r} = \ens{x\in X \mid \norm{x-a} < r} \qquad\text{respectivement}\qquad
         \bcB_X\p{a,r} = \ens{x\in X \mid \norm{x-a} \leq r}\]
    \end{definition}
    
    \begin{definition}{Voisinage relatif}{}
        Soit $a \in X$, si $V \supset \bcB_X\p{a, r}$ pour un $r > 0$.
    \end{definition}

    \(A \subset X\) est un ouvert relativement à $X$ lors $A$ est voisinage relatif de chacun de ses points. 
    \[ \forall a \in A, \exists r_n > 0 \mid \norm{x-a} < r_n \land x \in X \Rightarrow x \in A\]
    
    %
    $A$ est un fermé relativement à $X$ si son complémentaire dans $X$ est ouvert relativement à $X$.
    
    Caractérisation des fermé relatifs : $A \subset X$ fermé relativement à $X$ si $a_n \in A$ et $a_n \lima a \in X$, $\implies a \in A$.
    
    Caractérisation des ouverts relatifs : $A \subset X$ ouvert relativement si $A = U \cap X $ avec $U$ ouvert ; pour les fermés; $A = F \cap X$ avec $F$ fermé.
    
    \begin{proof}
        \begin{enumerate}
            \item \(U \cap X = A\), $U$ ouvert, soit \(a\in A, a \in U, \bcB\p{a,r} \subset U\) alors \[\bcB_X\p{a,r} = \bcB(a,r) \cap X \subset A\]
            \item Si $A$ est un ouvert relatif, soit $a\in A, \bcB_X\p{a,r} = \bcB(a,r) \cap X \subset A$ on pose alors $U = \bigcup_{a\in A} \bcB\p{a,r}$ ouvert vérifie bien \(U\cap X= A\)
        \end{enumerate}
        
    \end{proof}
    
    \section{Continuité}
    
    \subsection{Limite}
    
    $f : A \subset E \to F$, $a \in \overline{A}$. On dit que $\lim\limits_{\substack{x \to a\\ x \in A}} f\p{x} = \lim\limits_a f = \ell$ si :
    %
    \[ \forall \epsilon > 0,\qquad \exists \alpha > 0,\qquad \forall x \in A,\qquad \norm{x - a} \leq \alpha \implies \norm{f\p{x} - \ell} \leq \epsilon\]
    %
    Autrement dit, pour tout voisinage $V$ de $\ell$ et tout voisinage $U$ de $a$, $f\p{U \cap A} \subset V$.
    %
    Cette définition autorise $f \lima{0} \infty$, $f \lima{+\infty} \infty$, \dots (pour peut qu'on définisse la notion de voisinage de l'infini)
    %
    
    % sens direct
    \[\forall \epsilon > 0, \exists \alpha > 0, \norm{x-a} \leq \alpha \land x \in A \Rightarrow \norm{x-l} \leq \epsilon\]
    \(\bcV\) est un voisinage de $l$ on cherche $U$, \(\bcV \subset \bar{\bcB}(l,\epsilon)\) on sait que \(f\p{\bar{\bcB}(l,\epsilon)\cap A)} \subset \bar{\bcB}(l,\epsilon) \subset \bcV\) donc \(U = \bar{\bcB}(a,\alpha)\) convient.
    % reciproque 
    Soit $V= \bcB(l,\epsilon), \exists U \mid f(U \cap A \subset V, U \subset \bcB(a,\alpha)$ donc $\forall x \in A , \norm{x-a} \leq \alpha\implies  \norm{f(x) -l} < \epsilon$

    Caractérisation de \(\lim_a\forall (an) \to a \in A \Leftrightarrow f(an) \to l\)

    \begin{enumerate}
        \item[\(\Leftarrow\)] Par définition de la limite on a bien \( \norm{a_n-a} \leq \alpha\) à partir d'un certain rang, donc \(\norm{f(a_n) -l} \leq \epsilon\)
        \item[\(\Rightarrow\)] On suppose que \(f(a_n)\) ne converge pas, alors en faisant décroître \(\alpha\) et on a bien que \((a_n)\) ne converge pas vers \(a\)
    \end{enumerate}

    \begin{example}{}{}
        Soit $f:A\to B$ et $g : B \to C$ tel que $\lim_a f = b$ et $\lim_b g= l$ on a alors \(a\in\bar{A}\) donc \(f(a_n) \to b\) donc $b\in B$ et ainsi $\lim_a g \circ f = l$
        
    \end{example}
    
    \subsection{Cas où $F = \bdR^n$ (ev de dim finie}
    %
    Soit $f : A \subset E \to F$. Prop (admise) : toutes les normes sont équivalentes en dimension finie.
    
    \subsection{Continuité}
    %%alors on a pas de faute
    \subsection{Opérations}
    %t'ecrit bcp 
     
    \subsection{Caractérisation globale de la continuité}
     
    $f : E \to F$ $\bcC^0$ ssi pour tout $U$ ouvert de $F$, $f^{-1}\p{U}$ ouvert de $E$, ssi pour tout $F$ fermé $f^{-1}\p{F}$ fermé de $E$.
    
    
    \section{Continuité sur les EV}
    
    \subsection{présentation}
    
    \subsection{Norme sur l'espace des applications linéaires continues}
    
    On se place dans $\bcL_\bcC\p{E, V} = \Vect\p{\ens{u \in \bcL\p{E, V} \enstq u \in \bcC^0\p{E, F}}}$, l'espace vectoriel des applications linéaires continues. Pour $u \in \bcL_\bcC$, on pose :
    %
    \[ \tnorm{u} = \sup\limits_{\substack{x \in E\\ x \neq 0}} \dfrac{\norm{u\p{x}}}{\norm x} = \sup\limits_{\norm{x} = 1} \norm{u\p{x}}\]

    \section{Complétude*}
    
    \subsection{Présentation}

    \begin{definition}{Suite de Cauchy}{}
        \[ \forall \epsilon > 0,\qquad \exists n_0,\qquad p, q \geq n_0 \implies \norm{u_p - u_q} \leq \epsilon \]
        %
        $E$ est dit complet si toute suite de \textsc{Cauchy} converge, et $A \subset E$ est dit complète si toute suite de \textsc{Cauchy} d'éléments de $A$ converge dans $A$.
    \end{definition}
    
    \begin{property}{}{}
        $A \subset E$ complète ssi. $A$ fermé.
    \end{property}
    
    
    SI $E$ complet : CVA $\implies$ CV.
    
    \subsection{}
    
    COmment montrer que $E$ complet : on prend $x_n \in E$ de \textsc{Cauchy}.
    
    \begin{enumerate}
        \item On donne un sens à $x$ qui sera limite de $x_n$ ;
        \item  $x \in E$ ;
        \item $x_n \lima x$.
    \end{enumerate}
        
        $\bcL_\bcC\p{E, F}$ complet pour $\norm{u} = \sup\limits_{x \neq 0} \dfrac{\norm{u\p{x}}}{\norm{x}}$. Avec $u_n$ de \textsc{Cauchy}, $\norm{u_n -u_m} \leq \epsilon$ si $n, m \geq n_0$.
        %
        \[ \forall x \in E,\qquad \norm{u_n\p{x} - u_m\p{x}} \leq \epsilon\norm{x} \qquad\text{si}\qquad n, m \geq n_0\]
    
    \begin{enumerate}
        \item $x \in E$, mq $u_n\p{x} \in F$ complet converge vers $u\p{x}$
    \end{enumerate}
    
    $\bcC^0$ fermé dans $\bcB$ : plus tard.
    
    \begin{example}{}{}
        $E = \bcC^1\p{\intc{0, 1}, R}$ complet pour $N\p{f} = N_\infty\p{f} + N_\infty{f'}$. Soit $\p{f_n}_n$ de \textsc{Cauchy}, on a :
        
        
        On a $N\p{f_n - f_m} \leq \epsilon$, donc $N_\infty\p{f_n - f_m} \epsilon$ et $N_\infty\p{f_n' - f_m'} \leq \epsilon$.
        %
        \begin{enumerate}
            \itt $f_n \in \bcC^0$ complet pour $N_\infty$ : $f_n \lima f \in \bcC^0$
            
            \itt $f'_n \in \bcC^0$ complet pour $N_\infty$ : $f'_n \lima g \in \bcC^0$
        \end{enumerate}
        %
        IL manque donc que $f \in \bcC^1$, avec $f' = g$, puis $N\p{f - f_n} = N_\infty\p{f - f_n} + N_\infty\p{f' - f_n'} \lima{n \to +\infty} 0$.
        
        On a $f_n\p{x} = f_n\p{0} + \displaystyle\int_0^x f_n'$ d'où :
        %
        \[ \norm{\int_0^x f_n' - \int_0^n g} \leq \]
    \end{example}
    %coucouc
    
    \chapter{Séries numériques}
    
    \chaptertoc
    
    \section{Généralités}
    
    \begin{definition}{Somme directe}{}{}
        Soit une suite $\p{u_n}_{n \in \bdN} \in E^\bdN$. On appelle somme partie de rang $n$ la somme $S_n\p{u} = \displaystyle\sum_{i=0}^n u_i$.
        
        On dit que $\displaystyle\sum_{i=0}^\infty u_i$ converge si $S_n\p{u} \lima{n \to +\infty} \ell$, avec $\displaystyle\sum_{i=0}^\infty = \ell$.
    \end{definition}
    
    
    \newpage
    
    $\ell^1\p{\bdR} = \ens{\suite{u_n} \enstq \displaystyle\sum u_n \ \text{ACV}}$. $\bcN_1\p{u} = \sum\limits_{n \geq 0} \mod{u_n}$.
    
    Montrer que $\ell^1$ avec la norme $\bcN_1$ est complet.
    
    $u^p \in \ell^1$, $u^p = \p{u_n^p}_n$ de \textsc{Cauchy} :
    %
    \[ \forall \epsilon > 0,\qquad \exists n_0,\qquad p, q \geq n_0 \implies \sum_{n \geq 0} \mod{u_n^p - u_n^q} \leq \epsilon\]
    
    \begin{enumerate}
        \item Donner un sens à $u_n = \lim\limits_p u_n^p$ :
        %
        \[ \mod{u_n^p - u_n^q} \leq \bcN_1\p{u^p - u^q} \leq \epsilon \qquad\text{si} \ p, q \geq n_0\]
        %
        \ie $\p{u_n^p}_p$ de \textsc{Cauchy} dans $\bdR$ complet, admet une lim $u_n$.
        
        \item $\p{u_n} = u \in \bcl^1$.
        %
        \[ \mod{\bcN_1\p{u^p} - \bcN_1\p{u^q}} \leq \bcN_1\p{u^p - u^q} \qquad\text{donc}\qquad \p{\bcN_1\p{u^p}}_p \ \text{de \textsc{Cauchy} et bornée}\]
        %
        $\bcN_1\p{u^p} \leq M$ pour tout $p$, donc $\sum_{n \geq 0} \mod{u_n^p} \leq M$ pour tout $p$.
        
        Dans le cas fini, $\sum\limits_{n = 0}^N \mod{u_n^p} \leq M$ d'où pour $p \lima +\infty$, $\sum_{n=0}^N \mod{u_n} \leq M$, ce pour tout $N$ donc $\p{u_n}_n \in \ell^1$.
        
        \item $u^p \lima{\bcN_1} u$
        
        On a $\sum\limits_{n \geq 0} \mod{u_n^p - u_n^q} \leq \epsilon$ si $p, q \geq n_0$.
        
        Dans le cas fini, On a $\sum\limits_{n = 0}^N \mod{u_n^p - u_n^q} \leq \epsilon$ si $p, q \geq n_0$.
        
        Donc pour $q \lima +\infty$, on a $\sum\limits_{n = 0}^N \mod{u_n^p - u_n} \leq \epsilon$ si $p \geq n_0$.
        
        Pour tout $N$ donc $\sum\limits_{n \geq 0} \mod{u_n^p - u_n} \leq \epsilon$ si $p \geq n_0$, \ie $\bcN_1\p{u^p - u} \leq \epsilon$ si $p \geq n_0$.
    \end{enumerate}
    
    \begin{exercise}{}{}
        \[ \hg{\sum_{n \geq 2} \dfrac{\p{-1}^n}{n^\alpha + \p{-1}^nn^\beta}} = \sum_{n \geq 2} u_n \qquad\text{avec}\qquad \hg{\alpha \neq \beta}\]
        %
        \begin{enumerate}
            \itt Si $\beta > \alpha$, $u_n \asymp \dfrac{1}{n^\beta}$.
            
            \itt Si $\alpha > \beta$, $u_n \asymp \dfrac{\p{-1}^n}{n^\alpha}$.
            
            Si $\alpha > 1$ CVA, si $\alpha \leq 1$ non CVA, et si $\alpha \leq 0$ DV grossière.
            
            Pour $0 < \alpha \leq 1$ :
            %
            \[ \dfrac{1}{n^\alpha} \dfrac{\p{-1}^n}{1 + \p{-1}^nn^{\beta - \alpha}} = \dfrac{\p{-1}^n}{n^\alpha}\p{1 - \p{-1}^nn^{\beta- \alpha} + \bcO\p{n^{2\p{\beta- \alpha}}}} = \dfrac{\p{-1}^n}{n^\alpha} - \underbrace{\dfrac{1}{n^{2\p{\alpha - \beta}}} + \O{}{\dfrac{1}{n^{3\alpha - 2\beta}}}}_{v_n \asymp \dfrac{1}{n^{2\alpha - \beta}}}\]
            %
            Donc positivité, d'où CV si $2\alpha - \beta > 1$ et DV sinon.
        \end{enumerate}
    \end{exercise}
    
    Transformation d'Abel (TA) = ipp. $\sum_{n=p}^q a_nb_n$
    
    \chapter{Intégrales impropres}
    
    Etude de $\displaystyle \int_0^\infty f\p{t}\dif t$
    
    \chaptertoc
    
    \section{Généralités}
    
    \subsection{Continuité par morceaux}
    
    \begin{definition}{Fonction continue par morceaux}{}
        On dit qu'une fonction $f : \intc{a, b} \to \bdR, \bdC, E, \dots$ est continue par morceaux lorsque 
        %
        \[ \exists x_0 = a < x_1 < \dots < x_n = b\]
        %
        tels que $f$ est continue sur $\into{x_i, x_{i+1}}$, et $f$ admet une limite à droite et à gauche aux $x_i$.
    \end{definition}
    %
    \begin{notation}
        On note $f \in \bcC^0_{\mathfrak{m}}\p{\intc{a, b}, \dots}$.
    \end{notation}
    
    On remarque :
    %
    \begin{enumerate}
        \itt $f$ est $C^0_\text m$ sur $I$ un intervalle réel si elle est $C^0_\text m$ sur tout compact de $I$. Les points à problèmes peuvent s'accumuler mais seulement sur un bord de $I \not\in I$.
    \end{enumerate}
    
    \begin{example}{}{}
        La fonction $f\p{x} = \floor{\dfrac{1}{x}}$ est $C^0_\text m$ sur $\intor{a, \infty}$ mais pas sur $\into{0, \infty}$ (où $a > 0$).
        
        En effet, $f$ est $\bcC^0$ sur $\intol{\dfrac{1}{n+1}, \dfrac{1}{n}}$ avec $f\p{\dfrac{1}{n+1} + h} \lima{h \to 0^+} n$.
    \end{example}
    
    \subsection{Classes $\bcC^k$ par morceaux}
    
    \begin{definition}{}{}
        On dit qu'une fonction $f : \intc{a, b} \to \bdR, \bdC, E, \dots$ est de classe $\bcC^k$ par morceaux lorsque 
        %
        \[ \exists x_0 = a < x_1 < \dots < x_n = b\]
        %
        tels que $f$ est de classe $\bcC^k$ sur $\into{x_i, x_{i+1}}$, et $g_i = f_{\vert \into{x_i, x_{i+1}}}$ se prolonge en une fonction de classe $\bcC^k$ sur $\intc{x_i, x_{i+1}}$.
    \end{definition}
    %
    \begin{notation}
        On note $f \in \bcC^k_\text m\p{\intc{a, b}, \dots}$.
    \end{notation}
    
    On remarque de même :
    %
    \begin{enumerate}
        \itt La continuité par morceaux est bien le cas particulier de la classe $\bcC^0$.
        
        \itt De même, $f$ est $\bcC_m^k$ sur $I$ si $\bcC_m^k$ sur tout compact de $I$.
    \end{enumerate}
    
    \begin{theorem}{Caractérisation}{}
        $f$ est $\bcC_m^k$ sur $\intc{a, b}$ si
        %
        \begin{enumerate}
            \itast $f$ est $\bcC^k$ sur $\into{x_i, x_{i+1}}$
            
            \itast $f^{\p{k}}$ admet une limite à droite et à gauche aux $x_i$.
        \end{enumerate}
    \end{theorem}
    
    Autre CNS : existence de $f^{(j)}\p{x_i + 0}$ et $f^{(j)}\p{x_i - 0}$ pour $j \in \iint{0, k}$.
    
    \begin{example}{}{}
        Fonction en escalier.
    \end{example}
    
    \begin{theorem}{Théorème du prolongement}{}
        \begin{psse}
            \item $f$ est $\bcC^1$ sur $\intol{0, a}$. Si $f' \lima{0} \ell$, alors $f$ se prolonge en $F$ $\bcC^1$ sur $\intc{0, a}$.
            
            \item $f$ est $\bcC^1$ sur $I \setminus \ens{x_0}$. Si $f' \lima{x_0} \ell$, ...
            
            \item $f$ est $\bcC^k$ sur $\intol{0, a}$ avec $k \geq 1$. Si $f^{\p{k}} \lima{0} \ell_k$, alors $f$ se prolonge en $F$ $\bcC^k$ sur $\intc{0, a}$.
            
            \item $f$ est $\bcC^k$ sur $I \setminus \ens{x_0}$ avec $k \geq 1$. Si $f^{\p{k}} \lima{0} \ell_k$ et $f$ est $\bcC^0$ sur $I$, \dots
        \end{psse}
    \end{theorem}
    
    \subsection{CVA et SCV}
    
    $f$ $\bcC^0_{\mathfrak{m}}$ sur $\intor{a, b}$ ($b = \infty$ autorisé).
    
    $F\p{x} = \displaystyle\int_a^x f$.
    
    On dit $\displaystyle \int_a^b f$ CV et $\displaystyle \int_a^b f = \ell$ si $F \lima{b} \ell$
    
    \begin{property}{CVA entraîne CV}{}
        CVA entraîne CV.
    \end{property}
    %
    \begin{nproof}
        On suppose $\displaystyle\int_a^b \norm{f}$ CV. On remarque que :
        %
        \[ \int_a^x f = \int_a^c f + \int_c^x f \qquad\text{avec}\qquad x \geq c\]
        %
        $x \lima b$ : $\displaystyle \int_a^b f $ CV ssi. $\displaystyle\int_c^b f$ CV.
        
        Si oui, $\displaystyle\int_a^b f = \int_a^c f + \int_c^b f$. De plus, si CV, $\displaystyle\int_c^b f \lima{c \to b} 0$ (reste d'une $\int$ CV).
        
        Soit $F\p{x} = \displaystyle\int_a^x f$. O, veut montrer que $\lim\limits_b F$ existe :
        
        caractérisation seq $x_n \lima b$ mq $F\p{x_n}$ admet une limite.
        
        $\norm{F\p{x_n}} \leq \int_a^b \norm{f}$ est bornée. Compacité, mq unique va : si 2 va $\ell_1$ et $\ell_2$, deux extractrices $\varphi_1$ et $\varphi_2$, tels que :
        %
        \[ \int_a^{x_{\varphi_1\p{n}}} f \lima \ell_1 \qquad\et\qquad \int_a^{x_{\varphi_2\p{n}}} f \lima \ell_2\]
        %
        Ainsi $\displaystyle\int_{x_{\varphi_1\p{n}}}{x_{\varphi_2\p{n}}} f = \ell_2 - \ell_1$. Dès lors 
        %
        \[ \norm{\ell_2 - \ell_1} = \norm{\int_{x_{\varphi_1\p{n}}}^{x_{\varphi_2\p{n}}} f} \leq \int_{x_{\varphi_1\p{n}}}^{x_{\varphi_2\p{n}}} \norm{f} = \int_{x_{\varphi_1\p{n}}}^b \norm{f} - \int_{x_{\varphi_2\p{n}}}^b \norm{f} \lima{n \to +\infty} 0 - 0 = 0\]
        %
        Ainsi $\ell_1 = \ell_2$.
    \end{nproof}
    
    \section{Cas de la positivité}
    
    \subsection{Alternative}
    
    \subsection{}
    
    \subsection{Règle de l'équivalent}
    
    \subsection{Règle du $\bco$, $\bcO$}
    
    Si $f = \o{b}{g}$ \emph{- resp. $\O{b}{g}$ -} avec $g \geq 0$ positif, alors :
    %
    \begin{enumerate}
        \itt Si $\int_a^b g$ CV alors $\int_a^b f$ CV et $\int_x^b = \o{b}{\int_x^b g}$
        
        \itt Si $\int_a^b g$ DV alors $\int_a^x f = \o{b}{\int_a^x g}$.
    \end{enumerate}
    
    \subsection{Intégrales de Riemann}
    
    \begin{enumerate}
        \itt $\int_0^1 \dfrac{\dif t}{t^\alpha}$ CV si $\alpha < 1$ et DV si $\alpha \geq 1$
        
        \itt $\int_1^\infty \dfrac{\dif t}{t^\alpha}$ CV si $\alpha > 1$ et DV si $\alpha \leq 1$.
    \end{enumerate}
    
    \section{Méthodes pratiques}
    
    \subsection{Différence série intégrales}
    
    \begin{warning}{}{}
        \bf{PAS DE DIVERGENCE GROSSIÈRE !}
        
        \[ \int_0^\infty f \text{ CV } \implies f \text{ bornée ? \bf{FAUX !}} \qquad f \lima 0 \text{ ? \bf{FAUX!}}\]
    \end{warning}
    
    \subsection{Comparaison}
    
    $f$ $\bcC^0_{\mathfrak{m}}$ sur $\intor{0, \infty}$. 
    
    \begin{enumerate}
        \itt $t^2f\p{t} \lima 0 \implies$ CVA
        
        \itt $tf\p{t} \lima \infty$ avec $f \geq 0 \implies$ DV
    \end{enumerate}
    
    \begin{example}{}{}
        \begin{enumerate}
            \itt $\displaystyle\int_0^\infty e^{-\alpha t} \dif t$ CV avec $a > 0$ et $DV \leq 0$.
            
            \itt $\displaystyle\int_0^\infty e^{-\alpha t} \dif t$ si $\alpha > 0$.
        \end{enumerate}
    \end{example}
    
    \subsection{Changement de variable}
    
    \chapter{Suites et séries de fonctions}
    
    \chaptertoc
    
    \section{Convergence}
    
    \subsection{Convergence simple (CVS)}
    
    Suite $f_n : I \to E$. On dit $f_n$ simplement convergente vers $f$ sur $I$ si $\forall x \in I$, $f_n\p{x} \lima_{n \to +\infty} f\p{x}$
    
    I en général un intervalle réel ($I \subset F$ normé autorisé).\medskip
    
    Séries : $u_n : I\to E$
    
    On dit $\sum u_n$ CVS sur $I$ sur $\forall x \in I$, $\Sigma u_n\p{x}$ CV.
    
    \subsection{Convergence uniforme (CVU)}
    
    Suite $f_n : I \to E$. On a $f_n$ CVU sur $I$ vers $f$, si $N_\infty \p{f_n - f} \lima 0$\medskip
    
    Série $u_n : I \to E$, $\Sigma u_n$ CVU sur $I$ si $R_n$ CVU vers $0$ :
    %
    \[ \sup\limits_{x \in I} \norm{\sum_{k=n+1}^{+\infty} u_k\p{x}} \lima{n \to +\infty} 0\]
    
    $\sum u_n$ CVU sur $I$ si $\sum\limits_{n=0}^N u_n$ CVU sur $I$ (vers $\sum\limits_0^\infty u_n$). En effet :
    %
    \[ \sum_0^\infty u_n - S_N\p{u} = \sum_{N+1}^\infty u_n\]
    
    \subsection{Convergence normale (CVN) - que pour les séries}
    
    $u_n : I \to E$. On dit $\sum u_n$ CVN sur $I$ si $\sum N_\infty\p{u_n}$ CV.
    
    prop : CVN $\implies$ CVU : 
    %
    \[ \norm{\sum_{k=n+1}^{+\infty} u_k\p{x}} \leq \sum_{n+1}^\infty N_\infty\p{u_k}\]
    %
    Donc $\sup\limits_x \displaystyle \norm{\sum_{k=n+1}^\infty u_k} \leq \sum_{k=n+1}^\infty N_\infty\p{u_k} \lima{n \to \infty} 0$.
    
    \section{Théorèmes}
    
    \subsection{Continuité}
    
    Suite $f_n : I \to E$ avec $f_n \in \bcC^0$. Si $f_n$ CVU vers $f$ sur $I$ alors $f \in \bcC^0$ sur $I$.
    
    Série $u_n : I \to E$ avec $u_n \in \bcC^0$. Si $\sum u_n$ CVU/CVN sur $I$ alors $\sum u_n \in \bcC^0$ sur $I$.
    
    \subsection{Dérivabilité}
    
    Suite $f_n : I \subseteq \bdR \to E$ avec $f_n \in \bcC^1$. Si $f_n$ CVS sur $I$ vers $f$ et $f_n'$ CVU sur $I$ vers $g$, alors $f \in \bcC^1$ et $f' = g$.
    
    Notes :
    %
    \begin{itemize}
        \item CVU sur $f_n'$ essentielle
        \item Parfois on a vérifié la CVU de $f_n$ pour avoir $f \in \bcC^0$
    \end{itemize}
    
    \begin{align*}
         \left.\begin{array}{c}
        f_n \in \bcC^1  \\
        f_n \ \text{CVU vers} \ f\\
        f_n' \ \text{CVU vers} \ g
    \end{array}\right\rbrace &\implies \begin{array}{c}
        f \in \bcC^1\\
        f' = g
    \end{array}\\
    \left.\begin{array}{c}
        f_n \in \bcC^1 \ \text{sur} \ I \\
        f_n \ \text{CVS en} \ x_0 \in I\\
        f_n' \ \text{CVU vers} \ g
    \end{array}\right\rbrace &\implies \begin{array}{c}
        f_n \ \text{CVS sur} \ I \ \text{ver} f\\
        \p{\text{CVU sur tout compact de} \ I}\\
        f \in \bcC^1 \et f' = g
    \end{array}
    \end{align*}
    %
    Séries :
    %
    \begin{align*}
        \left.\begin{array}{c}
        u_n \in \bcC^1 \ \text{sur} \ I \subset \bdR \to E  \\
        \sum u_n \ \text{CVS sur} \ I\\
        \sum u_n' \ \text{CVU/CVN sur} \ I
    \end{array}\right\rbrace &\implies \begin{array}{c}
        \sum u_n \in \bcC^1\\
        \p{\sum u_n}' = \sum u_n'
    \end{array}\\
    \left.\begin{array}{c}
        u_n \in \bcC^1 \ \text{sur} \ I \subset \bdR \to E  \\
        \sum u_n \ \text{CVU sur} \ I\\
        \sum u_n' \ \text{CVU sur} \ I
    \end{array}\right\rbrace &\implies \begin{array}{c}
        \sum u_n \in \bcC^1\\
        \p{\sum u_n}' = \sum u_n'
    \end{array}\\
    \left.\begin{array}{c}
        u_n \in \bcC^1 \ \text{sur} \ I \subset \bdR \to E  \\
        \sum u_n \ \text{CVS en} \ x_0 \in I\\
        \sum u_n' \ \text{CVU sur} \ I
    \end{array}\right\rbrace &\implies \begin{array}{c}
        \sum u_n \ \text{CVS sur} \ I\\
        \text{(CVU sur tout compact)}\\
        \p{\sum u_n}' = \sum u_n'
    \end{array}
    \end{align*}
    
    \subsection{$\bcC^2$, $\bcC^k$}
    
    Suite :
    %
    \[\left.\begin{array}{c}
        f_n \in \bcC^k \ \text{sur} I\\
        f_n \ \text{CVS sur} \ I \ \text{vers} \ f\\
        f_n' \ \text{CVS sur} \ I \ \text{vers} \ f_1\\
        \vdots\\
        f_n^{\p{k-1}} \ \text{CVS sur} \ I \ \text{vers} \ f_{k-1}\\
        f_n^{\p{k}} \ \text{\underline{CVU} sur} \ I \ \text{vers} \ f_k
    \end{array}\right\rbrace \implies \begin{array}{c}
        \sum f \in \bcC^k \ \text{sur} \ I\\
        f^{\p{i}} = f_i \qquad i \leq k
    \end{array}\]
    %
    Série :
    %
    \[\left.\begin{array}{c}
        u_n \in \bcC^k\p{I, E}\\
        \sum u_n \ \text{CVS}\\
        \sum u_n' \ \text{CVS}\\
        \vdots\\
        \sum u_n^{\p{k-1}} \ \text{CVS}\\
        \sum u_n^{\p{k}} \ \text{\underline{CVU}}\\
    \end{array}\right\rbrace \implies \begin{array}{c}
        \sum f \in \bcC^k \ \text{sur} \ I\\
        f^{\p{i}} = f_i \qquad i \leq k
    \end{array}\]
    
    \subsection{$\bcC^\infty$}
    %
    Suite :
    %
    \[\left.\begin{array}{c}
        f_n \in \bcC^\infty\\
        f_n, f_n', \dots, f_n^{\p{(n_0 -1}} \ \text{CVS vers} \ f, f_1, \dots, f_{n_0 - 1}\\
        f_n^{\p{i}} \ \text{CVU} \ \text{pour} \ i \geq n_0
    \end{array}\right\rbrace \implies \begin{array}{c}
        \sum f \in \bcC^\infty \ \text{sur} \ I\\
        f^{\p{i}} = f_i \qquad \forall i
    \end{array}\]
    %
    Série : pareil
    
    Pratique :
    %
    \begin{itemize}
        \item CVU de $\sum u_n^{\p{k}}$, \qquad $\forall k \geq 0$
        
        (CVU de $\sum u_n^{\p{k}}$,\qquad $\forall k \geq 1$ et CVS pour $k = 0$)
        
        \itstar \textsc{Fubini} (vers l'an prochain).
    \end{itemize}
    
    \subsection{Intégration sur un segment}
    
    $f_n$ CVU sur $\intc{a, b}$ vers $f$.
    %
    \[ f_n \in \bcC^0_{\mathfrak{m}} \implies \int_a^b f_n \lima \int_a^b f\]
    %
    (CVU + Compacité)\medskip
    
    
    $\sum u_n$ CVU sur $\intc{a, b}$ :
    %
    \[ u_n \in \bcC^0_{\mathfrak{m}} \qquad \int_a^b \sum u_n = \sum \int_a^b u_n\]
    
    \section{Méthodes pratiques}
    
    \subsection{CVU d'une suite}
    %
    $f_n\p{x} = \dots$. CVS. CVU.
    
    CVS : on rédige $f_n \lima f$ sur $I$
    
    CVU : $\sup \mod{f_n - f}$ : variations de $f_n - f$, et majorer $\mod{\p{f_n - f}\p{x}}$ en choisissant $x$\medskip
    
    S'éloigner des points à problèmes. Par exemple, avec $0$ point à problème.
    
    Si $\p{f_n - f}\p{x}$, non sur $x \in \bdR_+$, mais sur $\into{0, +\infty}$, avec :
    %
    \[ \sup\limits_{\into{0, +\infty}} \mod{f_n - f} = \sup\limits_{\intor{0, +\infty}} \mod{f_n - f}\]
    
    \subsection{CVN d'une série}
    
    \begin{itemize}
        \item évaluer $N_\infty\p{u_n}$
        
        \item variations
        
        \item majorer $\mod{u_n\p{x}}$ indep de $x$
        
        \item (minorer $\mod{u_n\p{x}}$ indep de $x$ pour rédiger la non CVN)
        
        \item s'éloigner des points à problème
    \end{itemize}
    
    %
    exo : $f_n\p{x} = n^\alpha x^n$ sur $\intc{-1, 1}$. CVS CVU.
    
    
    \newpage
    
    \[ F\p{x} = \sum_{n \geq 1} \dfrac{1}{n^2 + x^2} \qquad\qquad x \in \bdR_+ \]
    %
    \begin{enumerate}
        \item CVS à $x$ fixé : $u_n\p{x} = \dfrac{1}{n^2 - x^2} = \bcO\p{\dfrac{1}{n^2}}$ donc CVA.
        
        CVN : $x \in \bdR_+$, et $\mod{u_n\p{x}} \leq \dfrac{1}{n^2}$ indépendamment de $x$. 
    \end{enumerate}
    
    \newpage
    
    Soit $F\p{x} = \sum\limits_{n \geq 0} \dfrac{e^{-nx}}{n^2 + 1}$
    
    \begin{enumerate}
        \item Pour $x \in \bdR_+$ CVS évidente, $\bcO\p{\dfrac{1}{n^2}}$ sinon divergence. 
    \end{enumerate}
    
    \chapter{Intégrales et interversion}
    
    \chaptertoc
    
    \section{Théorèmes d'interversions}
    
    \subsection{Limite et intégrale}
    
    $f_n : I \to E$ 
    
    \begin{itemize}
        \itt Convergence : $\suite{f_n}$ CVS sur $I$ vers $f$
        
        \itt Régularité : $f_n, f \in \bcC^0_\text m$ sur $I$
        
        \itt Domination : on dispose de $g \in L^1$ sur $I$ tq $\forall n$, $\norm{f_n} \leq g$
    \end{itemize}
    
    Dans ce cas, on a $\displaystyle\int_I f_n \lima{n \to +\infty} \int_I f$
    
    \subsection{Somme et intégrale}
    
    $f = \sum u_n$ avec $u_n \in \bcC^0$ sur $I \to E$
    
    \begin{itemize}
        \itt Convergence : $\sum u_n$ CVS sur $I$
        
        \itt Régularité : $u_n, \sum u_n \in \bcC^0_\text m$ sur $I$
        
        \itt Domination : $\displaystyle\sum_n \int_I \norm{u_n}$ CV
    \end{itemize}
    
    Dans ce cas, on a $\displaystyle \int_I \sum u_n = \sum \int_I u_n$
    
    \subsection{Hors programme : convergence monotone}
    
    $f = \sum u_n$ avec $u_n \in \bcC^0$ sur $I \to E$
    
    \begin{itemize}
        \itt Convergence : $\sum u_n$ CVS sur $I$
        
        \itt Régularité : $u_n, \sum u_n \in \bcC^0_\text m$ sur $I$
        
        \itt Monotonie : $u_n \geq 0$
    \end{itemize}
    
    Dans ce cas on a $f = \sum u_n$ qui est $\bbL^1$ sur $I$ ssi $\displaystyle \sum\int_I u_n$ CV. Si oui, $\displaystyle\int_I f = \sum \int_I u_n$.
    
    
    \section{Intégrales à paramètre}
    
    \newpage
    
    \begin{exercise}{}{}
        $F_n \in \bcC^0$ CVS vers $f \in \bcC^0$. $\p{f_n\p{x}}_n$ croissante, $I = \intc{0, 1}$. Montrer que $f_n$ CVU vers $f$.
        
        Pour cela, soit $\epsilon > 0$. Posons $F_n = \ens{x \in I, \enstq f_n\p{x} - f_{n+1}\p{x} \geq \epsilon}$.
        
        Montrer la convergence uniforme revient à montrer que $F_n$ est vide à partir d'un certain rang.
    \end{exercise}
    
    \chapter{Séries entières}
    
    \section{Rayn de convergence}
    
    $\suite{a_n} \in \bdC^\bdN$. En pratique il existe $R \in \intc{0, +\infty}$ tq si $\mod{z} < R$ alors $\sum a_nz^n$ ACV et si $\mod{z} > R$ la série diverge grossièrement. $R$ s'appelle rayon de convergence. Définition plus rigoureuse (lemme d'\textsc{Abel}) :
    %
    \[ R = \sup \ens{\rho \in \bdR_+ \enstq \exists M \in \bdR_+,\ \forall n \in \bdN,\quad a_n\rho^n \leq M}\]
    %
    Montrons que $\serie a_nz^n$ ACV si $\mod{z} < R$. Il existe $\mod{z} < \rho  R$ et l'on a $a_nz^n = a_n\rho^n \times \p{\dfrac{z}{\rho}}^n$.
    
    Ainsi $\mod{a_nz^n} = \mod{a_n\rho^n}\times\p{\dfrac{\mod{z}}{\rho}}^n$ ACV car $\mod{a_n\rho^n}$ bornée et $\dfrac{\mod{z}}{\rho} < 1$.
    
    Si $\mod{z} > R$, $a_n\mod{z}^n$ non borné, il existe $R < \rho < \mod{z}$, tel que $a_n\rho^n$ est non bornée. On conclut similairement (produit non borné).
    
    \begin{enumerate}
        \itt $\bsD\p{0, R}$ se nomme le disque de CV / l'ouvert de CV
        \itt $\bsC\p{0, R}$ se nomme cercle de CV (mal nommé, il n'y a pas forcément CV)
        \itt Il y a CVA sur l'ouvert de CV / le disque de CV
    \end{enumerate}
    
    \section{Méthodes de calcul}
    
    $a = \suite{a_n}$ et $R_a$ le rayon de convergence de $\sum a_nz^n$.
    
    \begin{enumerate}
        \itstar $R_a = R_{\mod{a}}$
        
        \itstar $0 \leq a_n \leq b_n \implies R_a \geq R_b$
        
        \itstar $R_{\lambda a} = R_a$
        
        \itstar $a_n \asymp b_n \implies R_a = R_b$ ou mieux, $\dfrac{1}{2}\mod{a_n} \leq \mod{b_n} \leq \dfrac{3}{2}\mod{a_n} \implies R_a = R_b$.
        
        ex $a_n = 2 + \sin n$, on a $1 \leq a_n \leq 3$ d'où $1 = R_1 \geq R_a \geq R_3 = 1$, \ie $R_a = 1$.
        
        autre ex, on verra $R_{\sfrac{1}{n}} = R_n = 1$ : $\dfrac{1}{n} \leq \mod{a_n} \leq r_n \implies R_a 1$ avec $1 \geq R_a \geq 1$.
    \end{enumerate}
    
    \section{d'Alembert}
    
    $\sum a_nz^n$ : $\mod{\dfrac{a_{n+1}}{a_n}} \lima{n \to +\infty} \ell \implies R = \dfrac{1}{\ell}$.
    
    Attention !!! $\sum a_nz^n$ de rayon $R$ n'implique PAS que $\mod{\dfrac{a_{n+1}}{a_n}} \lima{+\infty} R$.
    
    Théorème de d'Alembert : 
    
    
    \newpage
    
    \newpage
    
    \chapter{Probabilités}
    
    \begin{center}
        \emph{\EBGaramond De l'art de bien conditionner...}
    \end{center}
    
    \chaptertoc
    
    \section{Dénombrabilité}
    
    \subsection{Définitions}
    
    \begin{definition}{Partie finie et dénombrable}{}
        Une partie \hg{$A$ est dite finie} \emph{(resp. dénombrable)} si \hg{$A$ est en bijection avec une partie finie} \emph{(resp. dénombrable)} de l'ensemble des \hg{entiers naturels $\bdN$}.
    \end{definition}
    
    \textbf{\sffamily N.B.} La distinction entre fini et dénombrable se fait en France. Dans le monde anglo-saxon, le terme \guill{dénombrable} est utilisé pour désigner les deux cas. 
    
    \begin{property}{Parties des naturels}{}
        Soit $A \subset \bdN$. Soit \hg{$A$ est finie}, soit \hg{$A$ est en bijection avec $\bdN$}, \ie
        %
        \[ A \hookrightarrow \bdN \qquad\text{(s'injecte)} \implies A \ \text{dénombrable}\]
    \end{property}
    
    \begin{nproof}
        Soit $A \subset \bdN$. Si $A = \emptyset$, $A$ est finie. Sinon, considérons $A \neq \emptyset$.
        
        Soit $a_0 = \inf A$. Si $A = \ens{a_0}$, $A$ est finie. Sinon, soit $a_1 = \inf A \backslash \ens{a_0}$.\medskip
        
        On ré-itère le processus pour construire $a_1, a_2, \dots$ tant que c'est possible. Si on s'arrête, alors $A$ est finie. Sinon, on a $A = \ens{a_i}_{i \in \bdN}$. On a donc la bijection
        %
        \[ \p{a} : \begin{array}[t]{ccc}
            \bdN &\to A  \\
            i &\mapsto a_i 
        \end{array}\]
    \end{nproof}
    
    \subsection{Exemples}
    
    \begin{enumerate}
        \itt $A$ et $B$ dénombrables $\implies A \cup B$ dénombrable. Par exemple :
        %
        \[ 2\bdN \cup 2\bdN + 1 = \bdN\]
        
        \itt $A$ et $B$ dénombrables $\implies A \times B$ dénombrable. Notamment, $N \times \bdN$ dénombrable : carré et diagonales.
        
        \item $\bdQ$ dénombrable : $\bdQ \hookrightarrow \bdN \times \bdN*$.
    \end{enumerate}
    
    \begin{property}{Cantor}{}
        Pour un ensemble $X$, $\bcP\p{X}$ ne s'injecte pas dans $X$.
    \end{property}
    
    \begin{nproof}
        Classique, voir sup, ou cours d'info :)
    \end{nproof}
    
    \begin{property}{Cantor-Bernstein}
        Si $X \hookrightarrow Y$ et $Y \hookleftarrow X$, alors $X \approx Y$ (en bijection). 
    \end{property}
    
    \begin{nproof}
        En exo.
    \end{nproof}
    
    \begin{enumerate}
        \itt $\bdN^\bdN$ non dénombrable
        
        \item exo : l'ensembles des parties finies de $\bdN$ est dénombrable
        
        \item exo : l'ensemble des nombres algébriques sur $\bdQ$ est dénombrable.
    \end{enumerate}
    
    \section{Tribu}
    
    \subsection{Définition}
    
    \begin{definition}{}
        Une \hg{tribu $\bcT$} sur $\Omega$ est un ensemble de parties de $\Omega$ (\ie $\bcT \subset \bcP\p{\Omega}$) vérifiant :
        %
        \begin{psse}
            \item $\emptyset \in \bcT$ et $\Omega \in \bcT$
            
            \item $A \in \bcT \implies \overline A \in \bcT$ (où $\overline A = \Omega \backslash A$).
            
            \item $A_n \in \bcT$ pour $n \in \bdN \implies \displaystyle\bigcup_{n \geq 0} A_n \in \bcT$ et $\displaystyle\bigcap_{n \geq 0} A_n \in \bcT$.
        \end{psse}
    \end{definition}
    
    Exemples de tribu :
    %
    \begin{enumerate}
        \itt $\ens{\emptyset, \Omega}$ (tribu triviale)
        
        \itt $\bcP\p{\Omega}$ (tribu grossière)
    \end{enumerate}
    
    \subsection{Tribu engendrée}
    
    Soit $X \subset \bcP\p{\Omega}$. On veut définir la tribu engendrée par $X$ : c'est la plus petite tribu $\bcT$ telle que $X \subset \bcT$. 
    
    \begin{property}{}{}
        Pour $\bcT_i$, $i \in I$ des tribus, $\displaystyle\bigcap \bcT_i$ est une tribu.
    \end{property}
    
    La tribu engendrée par $X$ est donc l'intersection des tribu qui contiennent $X$.
    

    
    exo** : qu'est-ce qu'une tribu \textbf{finie} sur $\Omega$ ??
    
    \section{Probabilités}
    
    \subsection{Définition}
    
    \begin{definition}{Mesure de probabilité}{}
        Soit $\Omega$ un univers, $\bcT$ une tribu sur $\Omega$. Une \hg{mesure de probabilité} est une application 
        %
        \[ \bbP : \Omega \to \intc{0, 1} \]
        %
        telle que :
        %
        \begin{psse}
            \item $\bcP\p{\Omega} = 1$
            
            \item ($\sigma$-additivité) $\displaystyle\bbP\p{\bigsqcup_{n \in \bdN} A_n} = \sum_{n \in \bdN} \bbP\p{A_n}$.
        \end{psse}
    \end{definition}
    
    \subsection{De l'intérêt d'une tribu}
    
    Dans $\bdR$ tribu des boréliens : tribu engendrée par les ouverts de $\bdR$ (\cf premier ordinaux transfinis, \dots $\omega_1$ \dots). 
    
    Sur $\bdR$, la mesure $\mu : \begin{array}[t]{ccc}
        \bcP\p{\bdR} &\to& \bdR  \\
        X &\mapsto& \mu\p{X} 
    \end{array}$.
    
    $\mu\p{X}$ éventuellement infini. $\mu$ invariant par translation, respectant la $\sigma$-additivité.
    
    Considérons $\sfrac{\bdR}{\bdQ}$ : $x \asymp y \iff x - y \in \bdQ$. $\mathrm{Cl}\p{x} = x + \bdQ$.
    
    On peut remplacer $x_i$ par $x_i - q$, pour $q \in \bdQ$. On va donc supposer $x_i \in \intc{0, 1}$. Soit $X = \ens{x_i, i \in I}$ (NÉCESSITE AXIOME DU CHOIX).
    
    On a $X \subset \intc{0, 1}$ donc $0 \leq \mu\p{X} \leq 1$.
    
    \begin{enumerate}
        \itt (Attention difficile) On a $X + \intc{-1, 1} \cap \bdQ \supset \intc{0, 1}$, d'où $x \in \intc{0, 1}$ et $x \in \mathrm{Cl}\p{x_i}$, \ie $x = x_i + q$ et $q \in \intc{-1, 1} \cap \bdQ$.
        
        Donc $\mu\p{X + q} = \mu\p{X}$. Dès lors
        %
        \[ \mu\p{\intc{0, 1}} = 1 \leq \mu\p{X + \intc{-1, 1} \cap \bdQ} = \sum_{q \in \intc{-1, 1} \cap \bdQ} \mu\p{X + q}\]
        %
        Donc en conclusion $\mu\p{X} > 0$.
        
        \itt Mais $X + \intc{-1, 1} \cap \bdQ \subset \intc{-1, 2}$ d'où $\displaystyle\sum_{q \in \intc{-1, 1} \cap \bdQ} \mu\p{X + q} \leq 3$
        
        En conclusion $\mu\p{X} = 0$.
    \end{enumerate}
    
    Absurde, donc cet ensemble n'est pas mesurable.\bigskip\bigskip
    
    Soit $\bbP$ proba sur $\Omega, \bcT$. Les éléments de $\bcT$ s'appellent évènements. Exemple :
    %
    \begin{enumerate}
        \itt on tire à $P$ ou $F$ un certain nombre de fois : $X_1, X_2, \dots$
        
        \itt $\p{X_1 = 0}$
        
        \itt $\p{X_1 = 0, X_2 = 1, X_3 = 1}$
        
        \itt autre ex : $\Omega$ et $\bcT = \ens{\emptyset, \Omega}$. $\bbP\p{\emptyset} = 0$ et $\bbP\p{\Omega} = 1$.
    \end{enumerate}
    
    \subsection{Espérance conditionnelle}
    
    $X$ et $Y$ : $\bbP\p{X = x \enstq Y = y}$. Espérance conditionnelle :
    %
    \[ \bdE\p{X \enstq Y = y} = \sum_x x\bbP\p{X = x \enstq Y = y} = \varphi\p{y}\]
    %
    D'où $\bdE\p{X \enstq Y} = \varphi\p{Y}$. Intérêt :
    %
    \[ \bdE\p{\bdE\p{X \enstq Y}} = \bdE\p{X}\]
    %
    On a  $\bdE\p{X \enstq Y} = \varphi\p{y}$ donc
    %
    \begin{align*}
        \bdE\p{\bdE\p{X \enstq Y}} &= \bdE\p{\varphi\p{Y}} = \sum_y \varphi\p{Y}\bbP\p{Y = y} = \sum_{x, y}x\bbP\p{X = x \enstq Y = y}\bbP\p{Y = y}\\
        &= \sum_x x \sum_y \bbP\p{X = x, Y = y} = \sum_x x \bbP\p{X = x} = \bdE\p{X}
    \end{align*}
    %
    
    \section{Exemples}
    
A    \subsection{Fonctions génératrices}
    
    $X : \Omega \to \bdN$
    
    
    \newpage
    
    Considérons un jeu de pile ou face. On a $P$ le succès \guill{la pièce tombe sur pile}, de probabilité $0 < p \geq 1$, et $F$ l'échec \guill{la pièce tombe sur face} de probabilité $q = 1 - p$ (selon la terminologie d'une épreuve de \textsc{Bernoulli}). On a donc une variable aléatoire discrète de loi $\bcB\p{p}$. On observe la première apparition de $PP$.\medskip
    
    On considère la variable aléatoire $X$, telle que $X = k$ ssi. la première apparition de $PP$ se fait au $k$-ième tirage. On a :
    %
    \begin{align*}
        \p{X = 2} &= \p{PP} = \p{X_1 = X_2 = 1} = \p{X_1 = 1} \cap \p{X_2 = 1} \in \bcT\\
        \p{X = 3} &= \p{FPP}\\
        \p{X = 4} &= \p{\begin{array}{c}
            F  \\
            P
        \end{array}FPP} \qquad\text{union finie d'éléments de } \bcT\\
        \vdots
    \end{align*}
    %
    Bref, on est assuré de l'appartenance à la tribu $\bcT$. On considère alors
    %
    \[ \p{X = k} = (F\underbrace{ \cdots PP}_{\approx\; \p{X = k-1}}) \cup (PF\underbrace{\cdots PP}_{\approx\; \p{X = k-2}})\]
    %
    En notant $P_k = \bbP\p{X = k}$, on a donc la relation de récurrence
    %
    \[ P_k = qP_{k-1} + pqP_{k-2} \]
    %
    La suite $\suite{P_n}$ se calcule donc à l'aide d'une relation de récurrence, et selon les valeurs initiales $P_0 = 0$, $P_1 = 0$ et $P_2 = p^2$. Notons $\lambda$ et $\mu$ les deux racines du polynôme $Q\p{X} = X^2 - qX - pq$.
    
    On a $\Delta = \p{-q}^2 -4\p{-pq} = q^2 + 4pq > 0$, donc $\lambda$ et $\mu$ sont réels. Notons que :
    %
    \[ \lambda + \mu = q \qquad\et\qquad \lambda \mu = -pq\]
    %
    Donc $\lambda < 0 < \mu$ (choix arbitraire sans perte d'information) et $\mod{\lambda} < \mu$. Par ailleurs 
    %
    \[ Q\p{1} = 1 - q - pq = p - pq = p\p{1 - q} = p^2 > 0\]
    %
    Donc $\mod{\lambda} <  \mu < 1$, en vertu de quoi on a le caractère $\ell^1$ pour $\sum \lambda^k$ et $\sum \mu^k$. Finalement, on a $P_k = \alpha \lambda^k + \beta \mu^k$. On peut donc calculer $\bbP\p{X = \infty} = \lim\limits_{k \to +\infty} \bbP\p{X \geq k} = 0$ et $\bbP\p{X < \infty} = \displaystyle\sum$
    %
    \[ \bdE\p{X} = \sum_{k \geq 0} kP_k = \alpha\sum_{}\]
    
    \newpage
    
    Soit $X : \Omega \to E$ et $Y : \Omega \to F$ deux variables aléatoires discrètes, et une fonction $f : E \times F \to G$.
    
    Montrer que $Z = f\p{X, y}$ est une variable aléatoire discrète.\bigskip
    
    On prend $E = \ens{x_i}_{i \in \bdN}$ et $F = \ens{y_j}_{j \in \bdN}$ d'où $f\p{E, F} = \ens{f\p{x_i, y_j}}_{\p{i, j} \in \bdN^2}$ et $\bdN^2$ est dénombrable.
    
    Prenons $z \in f\p{E, F}$. On a $\p{Z = z} = \displaystyle\bigcup_{x, y \ \text{tq} \ f\p{x, y} = z} \p{X =x, Y = y}$ dénombrable car inclus dans $X \times Y$ dénombrable.\newpage
    
    Deux usines $U_1$, $U_2$, proportions d'objets défectueux $p_1$, $_2$. On se procure un sac de $n$ objets (même provenance). 
    
    Le premier est opérationnel.\newpage
    
    Deux jours de fortune initiale $a$ et $b$, avec $a + b = N$. Chaque partie $\bcB\p{p}$ pour le gain du premier joueur. On note 
    %
    \[ \bbP_n = \bbP\p{\text{le premier joueur ruine le deuxième avec au départ une fortune de $n$}} \]
    %
    On a $\bbP_n = p\bbP_{n+1} + q\bbP_{n-1}$, \ie 
    %
    \[\bbP_{n+2} = \dfrac{1}{p}\bbP_{n+1} + \dfrac{q}{p}\bbP_n \qquad\text{d'où l'on considère les $r$ tels que}\ r^2 - \dfrac{1}{p}r - \dfrac{q}{p} = 0\]
    %
    $\Delta = \dfrac{1}{p^2} - 4{1-p}{p} = \dfrac{1}{p}\p{\dfrac{1}{p} + 4p - 4}$
    
    \newpage
    
    \subsection*{Poissons}
    
    On considère une suite $\suiteZ{\lambda_n}$ telle que la série $\sum\limits_{n \geq 1} \lambda_n$ converge. Soient alors $\p{X_n}_{n \geq 1}$ variables aléatoires mutuellement indépendantes, telles que $X_n \rightsquigarrow \bcP\p{\lambda_n}$. On pose finalement $S = \sum\limits_{n \geq 1} X_n$
    
    \begin{enumerate}
        \item Montrer que, presque sûrement, on a $S < +\infty$.
        
        \boxans{
            Soit $n \in \bdN^*$, posons l'évènement $A_n = \displaystyle\bigcap_{k \geq n} \p{X_k = 0}$. Remarquons déjà que la suite $\suiteZ{A_n}$ est croissante. Que dire alors de $\lim\limits_{n \to +\infty}\bbP\p{A_n} $ ?
            %
            \[ \bbP\p{A_n} = \bbP\p{\bigcap_{k \geq n} \p{X_n = 0}} \eq{\bot} \prod_{k \geq n} \bbP\p{X_k = 0} = \prod_{k \geq n} e^{-\lambda_k}\dfrac{\lambda_k^0}{1!} = \exp{- \sum_{k \geq n} \lambda_k} \lima{n \to +\infty} \exp{0} = 1\]
            %
            Par croissance de $\suiteZ{A_n}$, on l'union $\displaystyle\bigcup_{n \geq 1} A_n$ est croissante, d'où
            %
            \[ \bbP\p{\bigcup_{n \geq 1} \bigcap_{k \geq n} \p{X_k = 0}} = 1\qquad\text{\ie}\qquad \bbP\p{X_n = 0 \ \text{sauf pour un ensemble fini de valeurs de}\ n} = 1\]
            %
            Posons maintenant $S_p\p{X_n} = \displaystyle\sum_{n = 1}^p X_n \rightsquigarrow \bcP\p{S_p\p{\lambda_n}}$. Montrons que $S \rightsquigarrow \bcP\p{\displaystyle\sum_{n \geq 1} \lambda_n}$. 
            
            On pose $\lambda = \displaystyle\sum_{n \geq 1} \lambda_n$, et on commence par montrer que $\bcP\p{S = k} = e^{-\lambda}\dfrac{\lambda^k}{k!}$.
            %On a une union croissante, d'où $\bbP\p{A_n} \lima{n \to +\infty} 1$
        }
        
        \item Déterminer la loi de $S$
        
        \item On pose maintenant $Y = \displaystyle\prod\limits_{n \geq 1} {p_n}^{X_n}$
        
        \item Montrer que, presque sûrement, on a  $Y < +\infty$.
        
        \item Donner l'espérance $\bdE\p{Y}$ de $Y$.
    \end{enumerate}
    
    \subsection*{Radelaker et trace}
    
    $X_{ij} \rightsquigarrow \textsc{Rademaker}, p = \sfrac{1}{2}$ \ie $\bdP\p{X = 1} = \bdP\p{X = -1} = \sfrac{1}{2}$, puis $M = \p{X_{ij}}_{1 \leq i, j \leq n}$.
    
    \begin{enumerate}
        \item $\bdE\p{\Tr{M}}$ ?
        
        \boxans{
            $\bdE\p{X_{ij}} = 0$ donc $\bdE\p{\Tr{M}} = 0$
        }
        
        \item $\bdE\p{\Tr{M^2}}$ ?
        
        \boxans{
            $\Tr{M^2} = \sum_{i, j} X_{ij}X_{ji}$. Or $\bdE\p{X_{ij}X_{ji}} = \begin{cases} 0 \ \text{si} \ i = j\\
            1 \ \text{sinon}
            \end{cases}$, donc $\bdE\p{\Tr{M^2}} = n$.
        }
        
        \item $\bdE\p{\Tr{M^3}}$ ?
        
        \boxans{
            $\p{M^2M}_{ii} = \displaystyle\sum_{k=1}^{n}\p{\sum_{p=1}^n X_{ip}X_{pk}}X_{ki}$ d'où $\bdE\p{\Tr{M^3}} = \displaystyle\sum_{i=1}^n\sum_{k=1}^n\sum_{p=1}^n \bdE\p{X_{ip}X_{pk}X_{ki}}$.
        }
    \end{enumerate}
    
    \chapter{Produit scalaire}
    
    \chaptertoc{}
    
    \section{Espaces préhilbertiens}
    
    \subsection{Définition}
    
    \begin{definition}{Produit scalaire}{}

        Soit $E$ un $\bdR$-espace vectoriel de (dimension finie ou non). On appelle \emph{produit scalaire sur $E$} une \hg{forme bilinéaire  $\p{\cdot \mid \cdot} : E \times E \to \bdR$} vérifiant :
        %
        \begin{enumerate}
            \itast \hg{$\p{\cdot \mid \cdot}$ est symétrique} :
            %
            \[ \forall \p{x, y} \in E^2,\qquad \p{x \mid y} = \p{y \mid x} \]
        
            \itast \hg{$\p{\cdot \mid \cdot}$ est positive} :
            %
            \[ \forall x \in E,\qquad \p{x \mid x} \geq 0 \]
    
            \itast \hg{$\p{\cdot \mid \cdot}$ est définie} :
            %
            \[ \forall x \in E,\qquad x = 0 \iff \p{x \mid x} = 0\] 
        \end{enumerate}
    \end{definition}
    
    A X-ENS, on pourra avoir des cas plus particuliers, par exemple $\bdK = \bdC$, ou $\p{\cdot \mid \cdot } : E \times E \to \bdC$. On pourrait avoir une propriété de sesquilinéarité :
    %
    \begin{enumerate}
        \itt $y \mapsto \p{x \mid y}$ linéaire
        \itt $x \mapsto \p{x \mid y}$ antilinéaire / semi-linéaire :
        %
        \[ \p{\lambda x + \mu x' \mid y} = \overline \lambda \p{x \mid y} + \overline{\mu}\p{x' \mid y}\]
        
        \itt $\p{x \mid y} = \overline{\p{y \mid x}}$
        
        \itt $\p{x \mid x} \in \bdRp$ si $x \neq 0$.
    \end{enumerate}
    
    Remarquons que $\p{x \mid y} = \overline{\p{y \mid x}} \implies \p{x \mid x} = \overline{\p{x \mid x}}$ \ie $\p{x \mid x} \in \bdR$.
    
    \subsection{Exemples}
    
    \begin{example}{sur $\bdR^n$}{}
        $X = \p{x_j}_{j \in \iint{0, n-1}}\in \bdR^n$. On peut définir
        %
        \[ \p{X \mid Y} = \sum_{i=0}^{n-1} x_iy_i = \mtrans XY\]
        %
        Il s'agit du produit scalaire canonique.
    \end{example}
    
    On peut généraliser à un $\bdR$-espace vectoriel $E$ de dimension finie :
    
    \begin{example}{sur $E$ de dimension finie}{}
        Considérons une base $\bcB = \p{e_i}_{i \in \iint{0, n-1}}$ de $E$. Pour $x \in E$, on écrit $x = \sum_{i=0}^{n-1} x_ie_i$.
        
        \[ \p{x \mid y} = \mtrans X Y = \sum x_iy_i\]
        %
        Il s'agit du produit scalaire canonique pour lequel $\bcB$ est orthonormé.
    \end{example}
    
    Sur $\bdC^n$, on pourrait définir $\p{X \mid Y} = \mtrans \overline{X} Y = \sum \overline{x_i}y_i$ : produit scalaire hermitien canonique.
    
    
    
    \subsection{Norme associé}
    
    $||x|| = \sqrt{(x|y)}$ c'est une norme (dite associé au produit scalaire)
    
    CS $$||(x|y)|| <  ||x|| * ||y||$$ \\
    
    
    inégalité triangle provient de CS.
    
    \subsection{BON / famille OrthoNormé}
    \begin{form}{BON / famille OrthoNormé}{}
        $(e_i)_{i=1,---,n)}$ BON si base $(e_i|e_j) = \delta_{ij}$
        \vspace{1cm}

        interet:  x=blabla 
        
    \end{form}
    
    
    \begin{form}{d-App}{}   % <----
        $Ker p = {x \forall i (x|e_i)=0}  $
    \end{form}

    \subsection{Orthonalisation}
    
    \begin{definition}
        E ev prehilbertien (ie ps)
        
        $(e_n)_{n \in \bcN}$ famille libre 
        
        $ON$ de Gram-Schmidt ( G S )
        \begin{enumerate}
            \itt \[ \scalebox{1.5}{\boxed{\exists (f_n)_{n>=0}  \bot  \text{ tq } \forall k \text{  Vect(}f_0 \text{ \--- }f_k) = \text{Vect(}e_0,\dots,e_k)}}   \]
            
            
            \itt  
        \end{enumerate}

        
    \end{definition}

    \newpage
    
    \begin{form}{suite du cours de maths}{}
        Si $i,j \bot $ seulement : $j=k \wedge i $ \\
        
        $sin \theta = (u(i')j') = (u(i) | j) * cst $        avec $cst > 0$\\
        
        $[(x|y) = det_{_{BON>0}} (x,y,z)]$\\
    \end{form}
    
    \begin{form}{exemple matrice}{}
        $k = \begin{pmatrix}
1 \\
2 \\ 
1
\end{pmatrix} \qquad i = \begin{pmatrix}
1 \\
0 \\
-1
\end{pmatrix}$
    
    ex $R$ rotation en $dim 3 \qquad$
    $u=e^a \qquad  a$ antisym
    \vspace{1cm}
    
    $\bsM a u = \begin{pmatrix}
\end{pmatrix}$
    
    \end{form}
    
    
    \section{TODO}
    \section{TODO}
    
    \newpage
    
    \subsection{Endormorphismes symétriques positifs}
    
    Dans $\bdC$, on ne peut appliquer certaines opérations algébriques que sur certains réels. Par exemple :
    %
    \begin{enumerate}
        \itt on ne peut calculer $\sqrt{x}$ que pour $x \in \bdR_+$ ;
        
        \itt on ne peut calculer $\ln{x}$ que pour $x \in \bdR_+^*$ ;
        
        \itt on ne peut dire que $x \leq y$ \emph{(respectivement $x < y$)} que pour $y - x \in \bdR_+$ \emph{(resp. $x - y \in \bdR_+^*$)}.
    \end{enumerate}
    %
    On remarquera que ces cas sont liés à la positivité, ou stricte positivité, d'un réel. Ces comportements se retrouvent dans certaines matrices symétriques, qu'on dit positives ou définies positives.
    
    \begin{definition}{Endomorphismes symétriques (défini) positifs}{}
        Soit \hg{$u \in \bcL\p{E}$} un endomorphisme de \hg{$\p{E, \phyavg{\mid}}$}, tel que \hg{$u \in \bcS\p{E}$ est symétrique}.
        %
        \begin{enumerate}
            \itast On dit que \hg{$u$ est positif} lorsque pour tout $x \in E$, on a \hg{$\phyavg{u\p{x} \mid x} \geq 0$}.
            
            \itast On dit que \hg{$u$ est défini positif} \emph{(ou \hg{strictement positif})} lorsque pour tout $x \in E \backslash \ens{0}$, on a \hg{$\phyavg{u\p{x} \mid x} > 0$}.
        \end{enumerate}
    \end{definition}
    
    Comme dans $\bdR$, on pourra utiliser les symboles $\geq$ et $>$. 
    
    \begin{notation}{}{}
        On note généralement \hg{$u \geq 0$} lorsque \hg{$u$ est positif}, et \hg{$u > 0$} lorsque \hg{$u$ est défini positif}. On note également \hg{$\bcS_+\p{E}$} l'ensemble des endomorphismes positifs de $E$ et \hg{$\bcS_+^\vdash\p{E}$} celui des endomorphismes définis positifs.
    \end{notation}
    
    On peut donner une condition nécessaire et suffisante de positivité et définie positivité d'un endomorphisme :
    
    \begin{theorem}{CNS Spectrale}{}
        Soit \hg{$u \in \bcL\p{E}$} un endomorphisme de \hg{$\p{E, \phyavg{\mid}}$}, tel que \hg{$u \in \bcS\p{E}$ est symétrique}.
        %
        \[ \hg{u \geq 0 \iff \Sp\p{u} \subset \bdR_+} \qquad\et\qquad \hg{u > 0 \iff \Sp\p{u} \subset \bdR_+^*}\]
    \end{theorem}
    
    \begin{nproof}
        Si $u \geq 0$, considérons $x$ un vecteur propre de $u$, et de valeur propre associée $\lambda$. On a 
        %
        \[ \lambda \norm{x}^2 = \phyavg{u\p{x} \mid x} \geq 0 \qquad\text{donc}\qquad x \geq 0 \]
        %
        Réciproquement, considérons $\p{e_i}_{1 \leq i \leq n}$ une base orthonormée de diagonalisation. On prend $x = \sum x_ie_i$, et l'on a :
        %
        \[ \phyavg{u\p{x} \mid x } = \sum \underbrace{\lambda_i}_{\geq 0} x_i^2 \geq 0 \]
        %
        La même démonstration s'applique pour $u > 0$.
    \end{nproof}
    
    On pourrait même écrire $u \leq v$ lorsque $v - u \in \bcS_+$ et $\p{u, v} \in \bcS$. Cette conception n'est cependant pas très intuitive :
    %
    \[ \begin{pNiceMatrix}
        1 & 0\\
        0 & 1
    \end{pNiceMatrix} \not\leq \begin{pNiceMatrix}
        1 & 2\\
        2 & 1
    \end{pNiceMatrix} \qquad\text{en effet,}\quad \Sp\begin{pNiceMatrix}
        0 & 2\\
        2 & 0
    \end{pNiceMatrix} = \ens{2, -2} \not\subset \bdR_+ \]
    
    \begin{exercise}{}{}
        \begin{center}
            Montrer que \hg{$\rho\p{u\transp u} = \rho\p{uu\transp}$}, autrement dit que \hg{$\tnorm{u} = \tnorm{u\transp}$}.
        \end{center}
        
        \begin{enumerate}
            \itt Remarquons déjà que $\tnorm{u\transp} \leq \tnorm{u}$ suffit, par involutivité de la transposition.
            
            \itt Soit $x \in E$ tel que $\norm{x} = 1$. On a
            %
            \[ \tnorm{u\transp}^2 = \phyavg{u\transp\p{x} \mid  u\transp\p{x}} = \]
        \end{enumerate}
    \end{exercise}
    
    Une propriété des endomorphismes symétriques positifs est l'existence d'une \guill{racine} :
    
    \begin{property}{Racine des endomorphismes symétriques positifs}{}
        Soit $u \in \bcS_+\p{E}$. Il existe un unique $v \in \bcS_+\p{E}$ tel que $v^2 = u$.
    \end{property}
    
    \newpage
    
    \chapter{Arithmétique}
    
    \chaptertoc
    
    \section{Groupes}
    
    \subsection{def}
    
    $\p{G, \star}$ groupe lorsque $\star :G \times G \to G$ 
    %
    \begin{enumerate}
        \itt Associative $x \star \p{y \star z} = \p{x \star y} \star z$
        
        \itt Existence d'un neutre : il existe $1_G \in G$ tel que pour tout $x \in G$, on a  $x \star 1_G = 1_G \star x = x$
        
        \itt Existence des symétriques : pour tout $x \in G$, il existe $x' \in G$ tel que $x \star x' = x' \star x = 1$
    \end{enumerate}
    
    \bigskip
    
    \begin{exercise}{}{}
        \hg{Soit $p \in \bdP$ un nombre premier strictement supérieur à $5$. Montrer que le développement en base 10 de $\sfrac{1}{p}$ est périodique de longueur de période divisant $p-1$.}\medskip
    
        Notons $d = o\p{p}$ dans $\bdZ/n\bdZ$, on a $10^d = 1$ mod $n$, donc il existe $Q \in \bdN$ tel que $10^d - 1 = nQ$. On a
        %
        \[ \dfrac{1}{n} = \dfrac{Q}{10^d - 1} \]
    \end{exercise}


\chapter{Equations différentelles linéaires}

\chaptertoc{}

\section{Aspects théoriques}

\subsection{Ordre 1}

\[ ay' + by = 0 \qquad a, b \in \bcC^0\p{I}\]

\begin{theorem}{Cauchy-Lipschitz}{}
    L'ensemble des solutions sur $I$ est un ev de dimension $1$
\end{theorem}

\[ ay' + by = c\]

CL : l'ensemble des solutions est un espace affine, dirigé par l'ev des solutions de l'eq homogène associée.
    
    
\end{document}